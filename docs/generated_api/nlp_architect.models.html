

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nlp_architect.models package &mdash; NLP Architect by IntelÂ® AI Lab 0.5.2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/install.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nlp_arch_theme.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:100,900" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="nlp_architect.models.absa package" href="nlp_architect.models.absa.html" />
    <link rel="prev" title="nlp_architect.data.cdc_resources.wordnet package" href="nlp_architect.data.cdc_resources.wordnet.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Jupyter Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">Model Zoo</a></li>
</ul>
<p class="caption"><span class="caption-text">NLP/NLU Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tagging/sequence_tagging.html">Sequence Tagging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sentiment.html">Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bist_parser.html">Dependency Parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intent.html">Intent Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lm.html">Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../information_extraction.html">Information Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transformers.html">Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../archived/additional.html">Additional Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Optimized Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quantized_bert.html">Quantized BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transformers_distillation.html">Transformers Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparse_gnmt.html">Sparse Neural Machine Translation</a></li>
</ul>
<p class="caption"><span class="caption-text">Solutions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../absa_solution.html">Aspect Based Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../term_set_expansion.html">Set Expansion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../trend_analysis.html">Trend Analysis</a></li>
</ul>
<p class="caption"><span class="caption-text">For Developers</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="nlp_architect_api_index.html">nlp_architect API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.api.html">nlp_architect.api package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.cli.html">nlp_architect.cli package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.common.html">nlp_architect.common package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.data.html">nlp_architect.data package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">nlp_architect.models package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.html">nlp_architect.models.absa package</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.bist.html">nlp_architect.models.bist package</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html">nlp_architect.models.cross_doc_coref package</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.transformers.html">nlp_architect.models.transformers package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.bist_parser">nlp_architect.models.bist_parser module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.chunker">nlp_architect.models.chunker module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.cross_doc_sieves">nlp_architect.models.cross_doc_sieves module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.crossling_emb">nlp_architect.models.crossling_emb module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.intent_extraction">nlp_architect.models.intent_extraction module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.most_common_word_sense">nlp_architect.models.most_common_word_sense module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.ner_crf">nlp_architect.models.ner_crf module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.np2vec">nlp_architect.models.np2vec module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.np_semantic_segmentation">nlp_architect.models.np_semantic_segmentation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.pretrained_models">nlp_architect.models.pretrained_models module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.tagging">nlp_architect.models.tagging module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models.temporal_convolutional_network">nlp_architect.models.temporal_convolutional_network module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp_architect.models">Module contents</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.nlp.html">nlp_architect.nlp package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.nn.html">nlp_architect.nn package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.pipelines.html">nlp_architect.pipelines package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.procedures.html">nlp_architect.procedures package</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.utils.html">nlp_architect.utils package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide.html">Developer Guide</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NLP Architect by IntelÂ® AI Lab</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="nlp_architect_api_index.html"><code class="docutils literal notranslate"><span class="pre">nlp\_architect</span></code> package</a> &raquo;</li>
        
      <li>nlp_architect.models package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="nlp-architect-models-package">
<h1>nlp_architect.models package<a class="headerlink" href="#nlp-architect-models-package" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">Â¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="nlp_architect.models.absa.html">nlp_architect.models.absa package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.absa.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp_architect.models.absa.inference.html">nlp_architect.models.absa.inference package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.inference.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.inference.html#module-nlp_architect.models.absa.inference.data_types">nlp_architect.models.absa.inference.data_types module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.inference.html#module-nlp_architect.models.absa.inference.inference">nlp_architect.models.absa.inference.inference module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.inference.html#module-nlp_architect.models.absa.inference">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nlp_architect.models.absa.train.html">nlp_architect.models.absa.train package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.acquire_terms">nlp_architect.models.absa.train.acquire_terms module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.data_types">nlp_architect.models.absa.train.data_types module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.generate_lexicons">nlp_architect.models.absa.train.generate_lexicons module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.rerank_terms">nlp_architect.models.absa.train.rerank_terms module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.rules">nlp_architect.models.absa.train.rules module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train.train">nlp_architect.models.absa.train.train module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.absa.train.html#module-nlp_architect.models.absa.train">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.absa.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.absa.html#module-nlp_architect.models.absa.utils">nlp_architect.models.absa.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.absa.html#module-nlp_architect.models.absa">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp_architect.models.bist.html">nlp_architect.models.bist package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp_architect.models.bist.eval.html">nlp_architect.models.bist.eval package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.bist.eval.html#subpackages">Subpackages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="nlp_architect.models.bist.eval.conllu.html">nlp_architect.models.bist.eval.conllu package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.bist.eval.conllu.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.bist.eval.conllu.html#module-nlp_architect.models.bist.eval.conllu.conll17_ud_eval">nlp_architect.models.bist.eval.conllu.conll17_ud_eval module</a></li>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.bist.eval.conllu.html#module-nlp_architect.models.bist.eval.conllu">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.bist.eval.html#module-nlp_architect.models.bist.eval">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#module-nlp_architect.models.bist.decoder">nlp_architect.models.bist.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#module-nlp_architect.models.bist.mstlstm">nlp_architect.models.bist.mstlstm module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#module-nlp_architect.models.bist.utils">nlp_architect.models.bist.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.bist.html#module-nlp_architect.models.bist">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html">nlp_architect.models.cross_doc_coref package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html">nlp_architect.models.cross_doc_coref.system package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html#subpackages">Subpackages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.sieves.html">nlp_architect.models.cross_doc_coref.system.sieves package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.sieves.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.sieves.html#module-nlp_architect.models.cross_doc_coref.system.sieves.run_sieve_system">nlp_architect.models.cross_doc_coref.system.sieves.run_sieve_system module</a></li>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.sieves.html#module-nlp_architect.models.cross_doc_coref.system.sieves.sieves">nlp_architect.models.cross_doc_coref.system.sieves.sieves module</a></li>
<li class="toctree-l6"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.sieves.html#module-nlp_architect.models.cross_doc_coref.system.sieves">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html#module-nlp_architect.models.cross_doc_coref.system.cdc_utils">nlp_architect.models.cross_doc_coref.system.cdc_utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html#module-nlp_architect.models.cross_doc_coref.system.sieves_container_init">nlp_architect.models.cross_doc_coref.system.sieves_container_init module</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.system.html#module-nlp_architect.models.cross_doc_coref.system">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html#module-nlp_architect.models.cross_doc_coref.sieves_config">nlp_architect.models.cross_doc_coref.sieves_config module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html#module-nlp_architect.models.cross_doc_coref.sieves_resource">nlp_architect.models.cross_doc_coref.sieves_resource module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.cross_doc_coref.html#module-nlp_architect.models.cross_doc_coref">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp_architect.models.transformers.html">nlp_architect.models.transformers package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#module-nlp_architect.models.transformers.base_model">nlp_architect.models.transformers.base_model module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#module-nlp_architect.models.transformers.quantized_bert">nlp_architect.models.transformers.quantized_bert module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#module-nlp_architect.models.transformers.sequence_classification">nlp_architect.models.transformers.sequence_classification module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#module-nlp_architect.models.transformers.token_classification">nlp_architect.models.transformers.token_classification module</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_architect.models.transformers.html#module-nlp_architect.models.transformers">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">Â¶</a></h2>
</div>
<div class="section" id="module-nlp_architect.models.bist_parser">
<span id="nlp-architect-models-bist-parser-module"></span><h2>nlp_architect.models.bist_parser module<a class="headerlink" href="#module-nlp_architect.models.bist_parser" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.bist_parser.BISTModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.bist_parser.</code><code class="descname">BISTModel</code><span class="sig-paren">(</span><em>activation='tanh'</em>, <em>lstm_layers=2</em>, <em>lstm_dims=125</em>, <em>pos_dims=25</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>BIST parser model class.
This class handles training, prediction, loading and saving of a BIST parser model.
After the model is initialized, it accepts a CoNLL formatted dataset as input, and learns to
output dependencies for new input.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>activation</strong> (<em>str</em><em>, </em><em>optional</em>) â Activation function to use.</li>
<li><strong>lstm_layers</strong> (<em>int</em><em>, </em><em>optional</em>) â Number of LSTM layers to use.</li>
<li><strong>lstm_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â Number of LSTM dimensions to use.</li>
<li><strong>pos_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â Number of part-of-speech embedding dimensions to use.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="nlp_architect.models.bist_parser.BISTModel.model">
<code class="descname">model</code><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The underlying LSTM model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><a class="reference internal" href="nlp_architect.models.bist.html#nlp_architect.models.bist.mstlstm.MSTParserLSTM" title="nlp_architect.models.bist.mstlstm.MSTParserLSTM">MSTParserLSTM</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.bist_parser.BISTModel.params">
<code class="descname">params</code><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Additional parameters and resources for the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">tuple</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.bist_parser.BISTModel.options">
<code class="descname">options</code><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.options" title="Permalink to this definition">Â¶</a></dt>
<dd><p>User model options.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body">dict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.bist_parser.BISTModel.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=10</em>, <em>dev=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Trains a BIST model on an annotated dataset in CoNLL file format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<em>str</em>) â Path to input dataset for training, formatted in CoNLL/U format.</li>
<li><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) â Number of learning iterations.</li>
<li><strong>dev</strong> (<em>str</em><em>, </em><em>optional</em>) â Path to development dataset for conducting evaluations.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.bist_parser.BISTModel.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Loads and initializes a BIST model from file.</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.bist_parser.BISTModel.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>evaluate=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Runs inference with the BIST model on a dataset in CoNLL file format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>str</em>) â Path to input CoNLL file.</li>
<li><strong>evaluate</strong> (<em>bool</em><em>, </em><em>optional</em>) â Write prediction and evaluation files to datasetâs folder.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The list of input sentences with predicted
dependencies attached.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">res (list of list of ConllEntry)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.bist_parser.BISTModel.predict_conll">
<code class="descname">predict_conll</code><span class="sig-paren">(</span><em>dataset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel.predict_conll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.predict_conll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Runs inference with the BIST model on a dataset in CoNLL object format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>dataset</strong> (<em>list of list of ConllEntry</em>) â Input in the form of ConllEntry objects.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The list of input sentences with predicted
dependencies attached.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">res (list of list of ConllEntry)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.bist_parser.BISTModel.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/bist_parser.html#BISTModel.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.bist_parser.BISTModel.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Saves the BIST model to file.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.chunker">
<span id="nlp-architect-models-chunker-module"></span><h2>nlp_architect.models.chunker module<a class="headerlink" href="#module-nlp_architect.models.chunker" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.chunker.SequenceChunker">
<em class="property">class </em><code class="descclassname">nlp_architect.models.chunker.</code><code class="descname">SequenceChunker</code><span class="sig-paren">(</span><em>use_cudnn=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceChunker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceChunker" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.chunker.SequenceTagger" title="nlp_architect.models.chunker.SequenceTagger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.chunker.SequenceTagger</span></code></a></p>
<p>A sequence Chunker model written in Tensorflow (and Keras) based SequenceTagger model.
The model uses only the chunking output of the model.</p>
<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceChunker.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>x</em>, <em>batch_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceChunker.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceChunker.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Predict labels given x.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> â samples for inference</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â forward pass batch size</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">tuple of numpy arrays of chunk labels</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.chunker.SequencePOSTagger">
<em class="property">class </em><code class="descclassname">nlp_architect.models.chunker.</code><code class="descname">SequencePOSTagger</code><span class="sig-paren">(</span><em>use_cudnn=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequencePOSTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequencePOSTagger" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.chunker.SequenceTagger" title="nlp_architect.models.chunker.SequenceTagger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.chunker.SequenceTagger</span></code></a></p>
<p>A sequence POS tagger model written in Tensorflow (and Keras) based SequenceTagger model.
The model uses only the chunking output of the model.</p>
<dl class="method">
<dt id="nlp_architect.models.chunker.SequencePOSTagger.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>x</em>, <em>batch_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequencePOSTagger.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequencePOSTagger.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Predict labels given x.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> â samples for inference</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â forward pass batch size</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">tuple of numpy arrays of POS labels</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.chunker.SequenceTagger">
<em class="property">class </em><code class="descclassname">nlp_architect.models.chunker.</code><code class="descname">SequenceTagger</code><span class="sig-paren">(</span><em>use_cudnn=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A sequence tagging model for POS and Chunks written in Tensorflow (and Keras) based on the
paper âDeep multi-task learning with low level tasks supervised at lower layersâ.
The model has 3 Bi-LSTM layers and outputs POS and Chunk tags.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>use_cudnn</strong> (<em>bool</em><em>, </em><em>optional</em>) â use GPU based model (CUDNNA cells)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>vocabulary_size</em>, <em>num_pos_labels</em>, <em>num_chunk_labels</em>, <em>char_vocab_size=None</em>, <em>max_word_len=25</em>, <em>feature_size=100</em>, <em>dropout=0.5</em>, <em>classifier='softmax'</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build a chunker/POS model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>vocabulary_size</strong> (<em>int</em>) â the size of the input vocabulary</li>
<li><strong>num_pos_labels</strong> (<em>int</em>) â the size of of POS labels</li>
<li><strong>num_chunk_labels</strong> (<em>int</em>) â the sie of chunk labels</li>
<li><strong>char_vocab_size</strong> (<em>int</em><em>, </em><em>optional</em>) â character vocabulary size</li>
<li><strong>max_word_len</strong> (<em>int</em><em>, </em><em>optional</em>) â max characters in a word</li>
<li><strong>feature_size</strong> (<em>int</em><em>, </em><em>optional</em>) â feature size - determines the embedding/LSTM layer                 hidden state size</li>
<li><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) â dropout rate</li>
<li><strong>classifier</strong> (<em>str</em><em>, </em><em>optional</em>) â classifier layer, âsoftmaxâ for softmax or âcrfâ for                 conditional random fields classifier. default is âsoftmaxâ.</li>
<li><strong>optimizer</strong> (<em>tensorflow.python.training.optimizer.Optimizer</em><em>, </em><em>optional</em>) â optimizer, if                 None will use default SGD (paper setup)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>batch_size=1</em>, <em>epochs=1</em>, <em>validation_data=None</em>, <em>callbacks=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Fit provided X and Y on built model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> â x samples</li>
<li><strong>y</strong> â y samples</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â batch size per sample</li>
<li><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) â number of epochs to run before ending training process</li>
<li><strong>validation_data</strong> (<em>optional</em>) â x and y samples to validate at the end of the epoch</li>
<li><strong>callbacks</strong> (<em>optional</em>) â additional callbacks to run with fitting</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>filepath</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load model from disk</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filepath</strong> (<em>str</em>) â file name of model</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.load_embedding_weights">
<code class="descname">load_embedding_weights</code><span class="sig-paren">(</span><em>weights</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.load_embedding_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.load_embedding_weights" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load word embedding weights into the model embedding layer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>weights</strong> (<em>numpy.ndarray</em>) â 2D matrix of word weights</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>x</em>, <em>batch_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Predict labels given x.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> â samples for inference</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â forward pass batch size</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">tuple of numpy arrays of pos and chunk labels</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.chunker.SequenceTagger.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>filepath</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/chunker.html#SequenceTagger.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.chunker.SequenceTagger.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model to disk</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filepath</strong> (<em>str</em>) â file name to save model</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.cross_doc_sieves">
<span id="nlp-architect-models-cross-doc-sieves-module"></span><h2>nlp_architect.models.cross_doc_sieves module<a class="headerlink" href="#module-nlp_architect.models.cross_doc_sieves" title="Permalink to this headline">Â¶</a></h2>
<dl class="function">
<dt id="nlp_architect.models.cross_doc_sieves.run_entity_coref">
<code class="descclassname">nlp_architect.models.cross_doc_sieves.</code><code class="descname">run_entity_coref</code><span class="sig-paren">(</span><em>topics: nlp_architect.common.cdc.topics.Topics</em>, <em>resources: nlp_architect.models.cross_doc_coref.system.sieves_container_init.SievesContainerInitialization</em><span class="sig-paren">)</span> &#x2192; List[nlp_architect.common.cdc.cluster.Clusters]<a class="reference internal" href="../_modules/nlp_architect/models/cross_doc_sieves.html#run_entity_coref"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.cross_doc_sieves.run_entity_coref" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Running Cross Document Coref on Entity mentions
:param topics: The Topics (with mentions) to evaluate
:param resources: (SievesContainerInitialization) resources for running the evaluation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">List of topics and mentions with predicted cross doc coref within each topic</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="nlp_architect.common.cdc.html#nlp_architect.common.cdc.cluster.Clusters" title="nlp_architect.common.cdc.cluster.Clusters">Clusters</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nlp_architect.models.cross_doc_sieves.run_event_coref">
<code class="descclassname">nlp_architect.models.cross_doc_sieves.</code><code class="descname">run_event_coref</code><span class="sig-paren">(</span><em>topics: nlp_architect.common.cdc.topics.Topics</em>, <em>resources: nlp_architect.models.cross_doc_coref.system.sieves_container_init.SievesContainerInitialization</em><span class="sig-paren">)</span> &#x2192; List[nlp_architect.common.cdc.cluster.Clusters]<a class="reference internal" href="../_modules/nlp_architect/models/cross_doc_sieves.html#run_event_coref"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.cross_doc_sieves.run_event_coref" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Running Cross Document Coref on event mentions
:param topics: The Topics (with mentions) to evaluate
:param resources: resources for running the evaluation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">List of clusters and mentions with predicted cross doc coref within each topic</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="nlp_architect.common.cdc.html#nlp_architect.common.cdc.cluster.Clusters" title="nlp_architect.common.cdc.cluster.Clusters">Clusters</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.crossling_emb">
<span id="nlp-architect-models-crossling-emb-module"></span><h2>nlp_architect.models.crossling_emb module<a class="headerlink" href="#module-nlp_architect.models.crossling_emb" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.crossling_emb.Discriminator">
<em class="property">class </em><code class="descclassname">nlp_architect.models.crossling_emb.</code><code class="descname">Discriminator</code><span class="sig-paren">(</span><em>input_data</em>, <em>Y</em>, <em>lr_ph</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#Discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.Discriminator" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="nlp_architect.models.crossling_emb.Discriminator.build_train_graph">
<code class="descname">build_train_graph</code><span class="sig-paren">(</span><em>disc_pred</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#Discriminator.build_train_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.Discriminator.build_train_graph" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Builds training graph for discriminator
:param disc_pred: Discriminator instance
:type disc_pred: object</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.crossling_emb.Generator">
<em class="property">class </em><code class="descclassname">nlp_architect.models.crossling_emb.</code><code class="descname">Generator</code><span class="sig-paren">(</span><em>src_ten</em>, <em>tgt_ten</em>, <em>emb_dim</em>, <em>batch_size</em>, <em>smooth_val</em>, <em>lr_ph</em>, <em>beta</em>, <em>vocab_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#Generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.Generator" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="nlp_architect.models.crossling_emb.Generator.build_train_graph">
<code class="descname">build_train_graph</code><span class="sig-paren">(</span><em>disc_pred</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#Generator.build_train_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.Generator.build_train_graph" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Builds training graph for generator
:param disc_pred: Discriminator instance
:type disc_pred: object</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.crossling_emb.WordTranslator">
<em class="property">class </em><code class="descclassname">nlp_architect.models.crossling_emb.</code><code class="descname">WordTranslator</code><span class="sig-paren">(</span><em>hparams</em>, <em>src_vec</em>, <em>tgt_vec</em>, <em>vocab_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Main network which does cross-lingual embeddings training</p>
<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.apply_procrustes">
<code class="descname">apply_procrustes</code><span class="sig-paren">(</span><em>sess</em>, <em>final_pairs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.apply_procrustes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.apply_procrustes" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies procrustes to W matrix for better mapping
:param sess: Tensorflow Session
:type sess: tf.session
:param final_pairs: Array of pairs which are mutual neighbors
:type final_pairs: ndarray</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.generate_xling_embed">
<code class="descname">generate_xling_embed</code><span class="sig-paren">(</span><em>sess</em>, <em>src_dict</em>, <em>tgt_dict</em>, <em>tgt_vec</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.generate_xling_embed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.generate_xling_embed" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Generates cross lingual embeddings
:param sess: Tensorflow session
:type sess: tf.session</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.report_metrics">
<em class="property">static </em><code class="descname">report_metrics</code><span class="sig-paren">(</span><em>iters</em>, <em>n_words_proc</em>, <em>disc_cost_acc</em>, <em>tic</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.report_metrics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.report_metrics" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reports metrics of how training is going</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>sess</em>, <em>local_lr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.run" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Runs whole GAN
:param sess: Tensorflow Session
:type sess: tf.session
:param local_lr: Learning rate
:type local_lr: float</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.run_discriminator">
<code class="descname">run_discriminator</code><span class="sig-paren">(</span><em>sess</em>, <em>local_lr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.run_discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.run_discriminator" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Runs discriminator part of GAN
:param sess: Tensorflow Session
:type sess: tf.session
:param local_lr: Learning rate
:type local_lr: float</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.run_generator">
<code class="descname">run_generator</code><span class="sig-paren">(</span><em>sess</em>, <em>local_lr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.run_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.run_generator" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Runs generator part of GAN
:param sess: Tensorflow Session
:type sess: tf.session
:param local_lr: Learning rate
:type local_lr: float</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Returns number of words processed</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.save_model">
<code class="descname">save_model</code><span class="sig-paren">(</span><em>save_model</em>, <em>sess</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.save_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.save_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Saves W in mapper as numpy array based on CSLS criterion
:param save_model: Save model if True
:type save_model: bool
:param sess: Tensorflow Session
:type sess: tf.session</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nlp_architect.models.crossling_emb.WordTranslator.set_lr">
<em class="property">static </em><code class="descname">set_lr</code><span class="sig-paren">(</span><em>local_lr</em>, <em>drop_lr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/crossling_emb.html#WordTranslator.set_lr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.crossling_emb.WordTranslator.set_lr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Drops learning rate based on CSLS criterion
:param local_lr: Learning Rate
:type local_lr: float
:param drop_lr: Drop learning rate by 2 if True
:type drop_lr: bool</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.intent_extraction">
<span id="nlp-architect-models-intent-extraction-module"></span><h2>nlp_architect.models.intent_extraction module<a class="headerlink" href="#module-nlp_architect.models.intent_extraction" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.intent_extraction.</code><code class="descname">IntentExtractionModel</code><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Intent Extraction model base class (using tf.keras)</p>
<dl class="method">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>epochs=1</em>, <em>batch_size=1</em>, <em>callbacks=None</em>, <em>validation=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train a model given input samples and target labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> â input samples</li>
<li><strong>y</strong> â input sample labels</li>
<li><strong>epochs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â number of epochs to train</li>
<li><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â batch size</li>
<li><strong>callbacks</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Callback</span></code>, optional) â Keras compatible callbacks</li>
<li><strong>validation</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, optional) â optional validation data
to be evaluated when training</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.input_shape">
<code class="descname">input_shape</code><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.input_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get input shape</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Type:</th><td class="field-body"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a trained model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>str</em>) â path to model file</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.load_embedding_weights">
<code class="descname">load_embedding_weights</code><span class="sig-paren">(</span><em>weights</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel.load_embedding_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.load_embedding_weights" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load word embedding weights into the model embedding layer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>weights</strong> (<em>numpy.ndarray</em>) â 2D matrix of word weights</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>x</em>, <em>batch_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the prediction of the model on given input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> â samples to run through the model</li>
<li><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â batch size:</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">predicted values by the model</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.intent_extraction.IntentExtractionModel.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em>, <em>exclude=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#IntentExtractionModel.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.IntentExtractionModel.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save model to path</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> (<em>str</em>) â path to save model</li>
<li><strong>exclude</strong> (<em>list</em><em>, </em><em>optional</em>) â a list of object fields to exclude when saving</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.intent_extraction.MultiTaskIntentModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.intent_extraction.</code><code class="descname">MultiTaskIntentModel</code><span class="sig-paren">(</span><em>use_cudnn=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#MultiTaskIntentModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.MultiTaskIntentModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.intent_extraction.IntentExtractionModel" title="nlp_architect.models.intent_extraction.IntentExtractionModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.intent_extraction.IntentExtractionModel</span></code></a></p>
<p>Multi-Task Intent and Slot tagging model (using tf.keras)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>use_cudnn</strong> (<em>bool</em><em>, </em><em>optional</em>) â use GPU based model (CUDNNA cells)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nlp_architect.models.intent_extraction.MultiTaskIntentModel.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>word_length</em>, <em>num_labels</em>, <em>num_intent_labels</em>, <em>word_vocab_size</em>, <em>char_vocab_size</em>, <em>word_emb_dims=100</em>, <em>char_emb_dims=30</em>, <em>char_lstm_dims=30</em>, <em>tagger_lstm_dims=100</em>, <em>dropout=0.2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#MultiTaskIntentModel.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.MultiTaskIntentModel.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build a model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word_length</strong> (<em>int</em>) â max word length (in characters)</li>
<li><strong>num_labels</strong> (<em>int</em>) â number of slot labels</li>
<li><strong>num_intent_labels</strong> (<em>int</em>) â number of intent classes</li>
<li><strong>word_vocab_size</strong> (<em>int</em>) â word vocabulary size</li>
<li><strong>char_vocab_size</strong> (<em>int</em>) â character vocabulary size</li>
<li><strong>word_emb_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â word embedding dimensions</li>
<li><strong>char_emb_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â character embedding dimensions</li>
<li><strong>char_lstm_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â character feature LSTM hidden size</li>
<li><strong>tagger_lstm_dims</strong> (<em>int</em><em>, </em><em>optional</em>) â tagger LSTM hidden size</li>
<li><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) â dropout rate</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.intent_extraction.MultiTaskIntentModel.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#MultiTaskIntentModel.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.MultiTaskIntentModel.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save model to path</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>str</em>) â path to save model</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.intent_extraction.Seq2SeqIntentModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.intent_extraction.</code><code class="descname">Seq2SeqIntentModel</code><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#Seq2SeqIntentModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.Seq2SeqIntentModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.intent_extraction.IntentExtractionModel" title="nlp_architect.models.intent_extraction.IntentExtractionModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.intent_extraction.IntentExtractionModel</span></code></a></p>
<p>Encoder Decoder Deep LSTM Tagger Model (using tf.keras)</p>
<dl class="method">
<dt id="nlp_architect.models.intent_extraction.Seq2SeqIntentModel.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>vocab_size</em>, <em>tag_labels</em>, <em>token_emb_size=100</em>, <em>encoder_depth=1</em>, <em>decoder_depth=1</em>, <em>lstm_hidden_size=100</em>, <em>encoder_dropout=0.5</em>, <em>decoder_dropout=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/intent_extraction.html#Seq2SeqIntentModel.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.intent_extraction.Seq2SeqIntentModel.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build the model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>vocab_size</strong> (<em>int</em>) â vocabulary size</li>
<li><strong>tag_labels</strong> (<em>int</em>) â number of tag labels</li>
<li><strong>token_emb_size</strong> (<em>int</em><em>, </em><em>optional</em>) â token embedding vector size</li>
<li><strong>encoder_depth</strong> (<em>int</em><em>, </em><em>optional</em>) â number of encoder LSTM layers</li>
<li><strong>decoder_depth</strong> (<em>int</em><em>, </em><em>optional</em>) â number of decoder LSTM layers</li>
<li><strong>lstm_hidden_size</strong> (<em>int</em><em>, </em><em>optional</em>) â LSTM layers hidden size</li>
<li><strong>encoder_dropout</strong> (<em>float</em><em>, </em><em>optional</em>) â encoder dropout</li>
<li><strong>decoder_dropout</strong> (<em>float</em><em>, </em><em>optional</em>) â decoder dropout</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.most_common_word_sense">
<span id="nlp-architect-models-most-common-word-sense-module"></span><h2>nlp_architect.models.most_common_word_sense module<a class="headerlink" href="#module-nlp_architect.models.most_common_word_sense" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense">
<em class="property">class </em><code class="descclassname">nlp_architect.models.most_common_word_sense.</code><code class="descname">MostCommonWordSense</code><span class="sig-paren">(</span><em>epochs</em>, <em>batch_size</em>, <em>callback_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_dim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.build" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.eval">
<code class="descname">eval</code><span class="sig-paren">(</span><em>valid_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.eval" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>train_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.fit" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.get_outputs">
<code class="descname">get_outputs</code><span class="sig-paren">(</span><em>valid_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.get_outputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.get_outputs" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>model_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.load" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.most_common_word_sense.MostCommonWordSense.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>save_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/most_common_word_sense.html#MostCommonWordSense.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.most_common_word_sense.MostCommonWordSense.save" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.ner_crf">
<span id="nlp-architect-models-ner-crf-module"></span><h2>nlp_architect.models.ner_crf module<a class="headerlink" href="#module-nlp_architect.models.ner_crf" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.ner_crf.NERCRF">
<em class="property">class </em><code class="descclassname">nlp_architect.models.ner_crf.</code><code class="descname">NERCRF</code><span class="sig-paren">(</span><em>use_cudnn=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Bi-LSTM NER model with CRF classification layer (tf.keras model)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>use_cudnn</strong> (<em>bool</em><em>, </em><em>optional</em>) â use cudnn LSTM cells</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>word_length</em>, <em>target_label_dims</em>, <em>word_vocab_size</em>, <em>char_vocab_size</em>, <em>word_embedding_dims=100</em>, <em>char_embedding_dims=16</em>, <em>tagger_lstm_dims=200</em>, <em>dropout=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build a NERCRF model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word_length</strong> (<em>int</em>) â max word length in characters</li>
<li><strong>target_label_dims</strong> (<em>int</em>) â number of entity labels (for classification)</li>
<li><strong>word_vocab_size</strong> (<em>int</em>) â word vocabulary size</li>
<li><strong>char_vocab_size</strong> (<em>int</em>) â character vocabulary size</li>
<li><strong>word_embedding_dims</strong> (<em>int</em>) â word embedding dimensions</li>
<li><strong>char_embedding_dims</strong> (<em>int</em>) â character embedding dimensions</li>
<li><strong>tagger_lstm_dims</strong> (<em>int</em>) â word tagger LSTM output dimensions</li>
<li><strong>dropout</strong> (<em>float</em>) â dropout rate</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>epochs=1</em>, <em>batch_size=1</em>, <em>callbacks=None</em>, <em>validation=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train a model given input samples and target labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> (numpy.ndarray or <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) â input samples</li>
<li><strong>y</strong> (<em>numpy.ndarray</em>) â input sample labels</li>
<li><strong>epochs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â number of epochs to train</li>
<li><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â batch size</li>
<li><strong>callbacks</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Callback</span></code>, optional) â Keras compatible callbacks</li>
<li><strong>validation</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, optional) â optional validation data
to be evaluated when training</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load model weights</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>str</em>) â path to load model from</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.load_embedding_weights">
<code class="descname">load_embedding_weights</code><span class="sig-paren">(</span><em>weights</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.load_embedding_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.load_embedding_weights" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load word embedding weights into the model embedding layer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>weights</strong> (<em>numpy.ndarray</em>) â 2D matrix of word weights</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>x</em>, <em>batch_size=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the prediction of the model on given input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (numpy.ndarray or <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) â input samples</li>
<li><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, optional) â batch size</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">predicted values by the model</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.ner_crf.NERCRF.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/ner_crf.html#NERCRF.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.ner_crf.NERCRF.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save model to path</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>str</em>) â path to save model weights</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.np2vec">
<span id="nlp-architect-models-np2vec-module"></span><h2>nlp_architect.models.np2vec module<a class="headerlink" href="#module-nlp_architect.models.np2vec" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.np2vec.NP2vec">
<em class="property">class </em><code class="descclassname">nlp_architect.models.np2vec.</code><code class="descname">NP2vec</code><span class="sig-paren">(</span><em>corpus</em>, <em>corpus_format='txt'</em>, <em>mark_char='_'</em>, <em>word_embedding_type='word2vec'</em>, <em>sg=0</em>, <em>size=100</em>, <em>window=10</em>, <em>alpha=0.025</em>, <em>min_alpha=0.0001</em>, <em>min_count=5</em>, <em>sample=1e-05</em>, <em>workers=20</em>, <em>hs=0</em>, <em>negative=25</em>, <em>cbow_mean=1</em>, <em>iterations=15</em>, <em>min_n=3</em>, <em>max_n=6</em>, <em>word_ngrams=1</em>, <em>prune_non_np=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np2vec.html#NP2vec"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np2vec.NP2vec" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initialize the np2vec model, train it, save it and load it.</p>
<dl class="method">
<dt id="nlp_architect.models.np2vec.NP2vec.is_marked">
<code class="descname">is_marked</code><span class="sig-paren">(</span><em>s</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np2vec.html#NP2vec.is_marked"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np2vec.NP2vec.is_marked" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Check if a string is marked.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>s</strong> (<em>str</em>) â string to check</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="nlp_architect.models.np2vec.NP2vec.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>np2vec_model_file</em>, <em>binary=False</em>, <em>word_ngrams=0</em>, <em>word2vec_format=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np2vec.html#NP2vec.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np2vec.NP2vec.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load the np2vec model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>np2vec_model_file</strong> (<em>str</em>) â the file containing the np2vec model to load</li>
<li><strong>binary</strong> (<em>bool</em>) â boolean indicating whether the np2vec model to load is in binary format</li>
<li><strong>word_ngrams</strong> (<em>int {1</em><em>,</em><em>0}</em>) â If 1, np2vec model to load uses word vectors with subword (</li>
<li><strong>information.</strong> (<em>ngrams</em><em>)</em>) â </li>
<li><strong>word2vec_format</strong> (<em>bool</em>) â boolean indicating whether the model to load has been stored in</li>
<li><strong>word2vec format.</strong> (<em>original</em>) â </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">np2vec model to load</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np2vec.NP2vec.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>np2vec_model_file='np2vec.model'</em>, <em>binary=False</em>, <em>word2vec_format=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np2vec.html#NP2vec.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np2vec.NP2vec.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the np2vec model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>np2vec_model_file</strong> (<em>str</em>) â the file containing the np2vec model to load</li>
<li><strong>binary</strong> (<em>bool</em>) â boolean indicating whether the np2vec model to load is in binary format</li>
<li><strong>word2vec_format</strong> (<em>bool</em>) â boolean indicating whether to save the model in original</li>
<li><strong>format.</strong> (<em>word2vec</em>) â </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.np_semantic_segmentation">
<span id="nlp-architect-models-np-semantic-segmentation-module"></span><h2>nlp_architect.models.np_semantic_segmentation module<a class="headerlink" href="#module-nlp_architect.models.np_semantic_segmentation" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier">
<em class="property">class </em><code class="descclassname">nlp_architect.models.np_semantic_segmentation.</code><code class="descname">NpSemanticSegClassifier</code><span class="sig-paren">(</span><em>num_epochs</em>, <em>callback_args</em>, <em>loss='binary_crossentropy'</em>, <em>optimizer='adam'</em>, <em>batch_size=128</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>NP Semantic Segmentation classifier model (based on tf.Keras framework).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>num_epochs</strong> (<em>int</em>) â number of epochs to train the model</li>
<li><strong>**callback_args</strong> (<em>dict</em>) â callback args keyword arguments to init a Callback for the model</li>
<li><strong>loss</strong> â the modelâs cost function. Default is âtf.keras.losses.binary_crossentropyâ loss</li>
<li><strong>optimizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.optimizers</span></code>) â the modelâs optimizer. Default is âadamâ</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_dim</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build the modelâs layers
:param input_dim: the first layerâs input_dim
:type input_dim: int</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.eval">
<code class="descname">eval</code><span class="sig-paren">(</span><em>test_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.eval" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Evaluate the modelâs test_set on error_rate, test_accuracy_rate and precision_recall_rate</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>test_set</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) â The test set</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">loss, binary_accuracy, precision, recall and f1 measures</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tuple(float)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>train_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train and fit the model on the datasets</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_set</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) â The train set</li>
<li><strong>args</strong> â callback_args and epochs from ArgParser input</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.get_outputs">
<code class="descname">get_outputs</code><span class="sig-paren">(</span><em>test_set</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.get_outputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.get_outputs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Classify the dataset on the model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>test_set</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) â The test set</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">modelâs predictions</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>model_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load pre-trained modelâs .h5 file to NpSemanticSegClassifier object</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model_path</strong> (<em>str</em>) â local path for loading the model</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>model_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#NpSemanticSegClassifier.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.NpSemanticSegClassifier.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the modelâs prm file in model_path location</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model_path</strong> (<em>str</em>) â local path for saving the model</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nlp_architect.models.np_semantic_segmentation.f1">
<code class="descclassname">nlp_architect.models.np_semantic_segmentation.</code><code class="descname">f1</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#f1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.f1" title="Permalink to this definition">Â¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> â </li>
<li><strong>y_pred</strong> â </li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Returns:</p>
</dd></dl>

<dl class="function">
<dt id="nlp_architect.models.np_semantic_segmentation.precision_score">
<code class="descclassname">nlp_architect.models.np_semantic_segmentation.</code><code class="descname">precision_score</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#precision_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.precision_score" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Precision metric.</p>
<p>Only computes a batch-wise average of precision.</p>
<p>Computes the precision, a metric for multi-label classification of
how many selected items are relevant.</p>
</dd></dl>

<dl class="function">
<dt id="nlp_architect.models.np_semantic_segmentation.recall_score">
<code class="descclassname">nlp_architect.models.np_semantic_segmentation.</code><code class="descname">recall_score</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/np_semantic_segmentation.html#recall_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.np_semantic_segmentation.recall_score" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Recall metric.</p>
<p>Only computes a batch-wise average of recall.</p>
<p>Computes the recall, a metric for multi-label classification of
how many relevant items are selected.</p>
</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.pretrained_models">
<span id="nlp-architect-models-pretrained-models-module"></span><h2>nlp_architect.models.pretrained_models module<a class="headerlink" href="#module-nlp_architect.models.pretrained_models" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.pretrained_models.AbsaModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">AbsaModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#AbsaModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.AbsaModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained ABSA model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.AbsaModel.files">
<code class="descname">files</code><em class="property"> = ['rerank_model.h5']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.AbsaModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.AbsaModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/absa/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.AbsaModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.BistModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">BistModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#BistModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.BistModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained BIST model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.BistModel.files">
<code class="descname">files</code><em class="property"> = ['bist-pretrained.zip']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.BistModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.BistModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/dep_parse/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.BistModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.ChunkerModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">ChunkerModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#ChunkerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.ChunkerModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained Chunker model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.ChunkerModel.files">
<code class="descname">files</code><em class="property"> = ['model.h5', 'model_info.dat.params']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.ChunkerModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.ChunkerModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/chunker/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.ChunkerModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.IntentModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">IntentModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#IntentModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.IntentModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained Intent model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.IntentModel.files">
<code class="descname">files</code><em class="property"> = ['model_info.dat', 'model.h5']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.IntentModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.IntentModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/intent/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.IntentModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.MrcModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">MrcModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#MrcModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.MrcModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained MRC model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.MrcModel.files">
<code class="descname">files</code><em class="property"> = ['mrc_data.zip', 'mrc_model.zip']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.MrcModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.MrcModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/mrc/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.MrcModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.NerModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">NerModel</code><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#NerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.NerModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="nlp_architect.models.pretrained_models.PretrainedModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.pretrained_models.PretrainedModel</span></code></a></p>
<p>Download and process (unzip) pre-trained NER model</p>
<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.NerModel.files">
<code class="descname">files</code><em class="property"> = ['model_v4.h5', 'model_info_v4.dat']</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.NerModel.files" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nlp_architect.models.pretrained_models.NerModel.sub_path">
<code class="descname">sub_path</code><em class="property"> = 'models/ner/'</em><a class="headerlink" href="#nlp_architect.models.pretrained_models.NerModel.sub_path" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.pretrained_models.PretrainedModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.pretrained_models.</code><code class="descname">PretrainedModel</code><span class="sig-paren">(</span><em>model_name</em>, <em>sub_path</em>, <em>files</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#PretrainedModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.PretrainedModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generic class to download the pre-trained models</p>
<p>Usage Example:</p>
<p>chunker = ChunkerModel.get_instance()
chunker2 = ChunkerModel.get_instance()
print(chunker, chunker2)
print(âLocal File path = â, chunker.get_file_path())
files_models = chunker2.get_model_files()
for idx, file_name in enumerate(files_models):</p>
<blockquote>
<div>print(str(idx) + â: â + file_name)</div></blockquote>
<dl class="method">
<dt id="nlp_architect.models.pretrained_models.PretrainedModel.get_file_path">
<code class="descname">get_file_path</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#PretrainedModel.get_file_path"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.PretrainedModel.get_file_path" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return local file path of downloaded model files</p>
</dd></dl>

<dl class="classmethod">
<dt id="nlp_architect.models.pretrained_models.PretrainedModel.get_instance">
<em class="property">classmethod </em><code class="descname">get_instance</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#PretrainedModel.get_instance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.PretrainedModel.get_instance" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Static instance access method
:param cls: Calling class
:type cls: Class name</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.pretrained_models.PretrainedModel.get_model_files">
<code class="descname">get_model_files</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/pretrained_models.html#PretrainedModel.get_model_files"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.pretrained_models.PretrainedModel.get_model_files" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return individual file names of downloaded models</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.tagging">
<span id="nlp-architect-models-tagging-module"></span><h2>nlp_architect.models.tagging module<a class="headerlink" href="#module-nlp_architect.models.tagging" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.tagging.InputFeatures">
<em class="property">class </em><code class="descclassname">nlp_architect.models.tagging.</code><code class="descname">InputFeatures</code><span class="sig-paren">(</span><em>input_ids</em>, <em>char_ids</em>, <em>mask=None</em>, <em>label_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#InputFeatures"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.InputFeatures" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A single set of features of data.</p>
</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.tagging.NeuralTagger">
<em class="property">class </em><code class="descclassname">nlp_architect.models.tagging.</code><code class="descname">NeuralTagger</code><span class="sig-paren">(</span><em>embedder_model</em>, <em>word_vocab: nlp_architect.utils.text.Vocabulary</em>, <em>labels: List[str] = None</em>, <em>use_crf: bool = False</em>, <em>device: str = 'cpu'</em>, <em>n_gpus=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nlp_architect.models.TrainableModel" title="nlp_architect.models.TrainableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp_architect.models.TrainableModel</span></code></a></p>
<p>Simple neural tagging model
Supports pytorch embedder models, multi-gpu training, KD from teacher models</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>embedder_model</strong> â pytorch embedder model (valid nn.Module model)</li>
<li><strong>word_vocab</strong> (<a class="reference internal" href="nlp_architect.utils.html#nlp_architect.utils.text.Vocabulary" title="nlp_architect.utils.text.Vocabulary"><em>Vocabulary</em></a>) â word vocabulary</li>
<li><strong>labels</strong> (<em>List</em><em>, </em><em>optional</em>) â list of labels. Defaults to None</li>
<li><strong>use_crf</strong> (<em>bool</em><em>, </em><em>optional</em>) â use CRF a the classifier (instead of Softmax). Defaults to False.</li>
<li><strong>device</strong> (<em>str</em><em>, </em><em>optional</em>) â device backend. Defatuls to âcpuâ.</li>
<li><strong>n_gpus</strong> (<em>int</em><em>, </em><em>optional</em>) â number of gpus. Default to 0.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="staticmethod">
<dt id="nlp_architect.models.tagging.NeuralTagger.batch_mapper">
<em class="property">static </em><code class="descname">batch_mapper</code><span class="sig-paren">(</span><em>batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.batch_mapper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.batch_mapper" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Map batch to correct input names</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.convert_to_tensors">
<code class="descname">convert_to_tensors</code><span class="sig-paren">(</span><em>examples: List[nlp_architect.data.sequential_tagging.TokenClsInputExample], max_seq_length: int = 128, max_word_length: int = 12, pad_id: int = 0, labels_pad_id: int = 0, include_labels: bool = True</em><span class="sig-paren">)</span> &#x2192; torch.utils.data.dataset.TensorDataset<a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.convert_to_tensors"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.convert_to_tensors" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Convert examples to valid tagger dataset</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>examples</strong> (<em>List</em><em>[</em><a class="reference internal" href="nlp_architect.data.html#nlp_architect.data.sequential_tagging.TokenClsInputExample" title="nlp_architect.data.sequential_tagging.TokenClsInputExample"><em>TokenClsInputExample</em></a><em>]</em>) â List of examples</li>
<li><strong>max_seq_length</strong> (<em>int</em><em>, </em><em>optional</em>) â max words per sentence. Defaults to 128.</li>
<li><strong>max_word_length</strong> (<em>int</em><em>, </em><em>optional</em>) â max characters in a word. Defaults to 12.</li>
<li><strong>pad_id</strong> (<em>int</em><em>, </em><em>optional</em>) â padding int id. Defaults to 0.</li>
<li><strong>labels_pad_id</strong> (<em>int</em><em>, </em><em>optional</em>) â labels padding id. Defaults to 0.</li>
<li><strong>include_labels</strong> (<em>bool</em><em>, </em><em>optional</em>) â include labels in dataset. Defaults to True.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">TensorDataset for given examples</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">TensorDataset</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>data_set: torch.utils.data.dataloader.DataLoader</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.evaluate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Run evaluation on given dataloader</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data_set</strong> (<em>DataLoader</em>) â a data loader to run evaluation on</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">logits, labels (if labels are given)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.evaluate_predictions">
<code class="descname">evaluate_predictions</code><span class="sig-paren">(</span><em>logits</em>, <em>label_ids</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.evaluate_predictions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.evaluate_predictions" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Evaluate given logits on truth labels</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>logits</strong> â logits of model</li>
<li><strong>label_ids</strong> â truth label ids</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dictionary containing P/R/F1 metrics</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.extract_labels">
<code class="descname">extract_labels</code><span class="sig-paren">(</span><em>label_ids</em>, <em>logits</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.extract_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.extract_labels" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.get_logits">
<code class="descname">get_logits</code><span class="sig-paren">(</span><em>batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.get_logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.get_logits" title="Permalink to this definition">Â¶</a></dt>
<dd><p>get model logits from given input</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.get_optimizer">
<code class="descname">get_optimizer</code><span class="sig-paren">(</span><em>opt_fn=None</em>, <em>lr: int = 0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.get_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.get_optimizer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get default optimizer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lr</strong> (<em>int</em><em>, </em><em>optional</em>) â learning rate. Defaults to 0.001.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">optimizer</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">torch.optim.Optimizer</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>examples: List[nlp_architect.data.sequential_tagging.TokenClsInputExample], batch_size: int = 64</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.inference" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Do inference on given examples</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>examples</strong> (<em>List</em><em>[</em><a class="reference internal" href="nlp_architect.data.html#nlp_architect.data.sequential_tagging.TokenClsInputExample" title="nlp_architect.data.sequential_tagging.TokenClsInputExample"><em>TokenClsInputExample</em></a><em>]</em>) â examples</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â batch size. Defaults to 64.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">a list of tuples of tokens, tags predicted by model</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">List(tuple)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="nlp_architect.models.tagging.NeuralTagger.load_model">
<em class="property">classmethod </em><code class="descname">load_model</code><span class="sig-paren">(</span><em>model_path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.load_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.load_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a tagger model from given path</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model_path</strong> (<em>str</em>) â model path</li>
<li><strong>NeuralTagger</strong> â tagger model loaded from path</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.save_model">
<code class="descname">save_model</code><span class="sig-paren">(</span><em>output_dir: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.save_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.save_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save model to path</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>output_dir</strong> (<em>str</em>) â output directory</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.to">
<code class="descname">to</code><span class="sig-paren">(</span><em>device='cpu'</em>, <em>n_gpus=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.to" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Put model on given device</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>device</strong> (<em>str</em><em>, </em><em>optional</em>) â device backend. Defaults to âcpuâ.</li>
<li><strong>n_gpus</strong> (<em>int</em><em>, </em><em>optional</em>) â number of gpus. Defaults to 0.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>train_data_set: torch.utils.data.dataloader.DataLoader</em>, <em>dev_data_set: torch.utils.data.dataloader.DataLoader = None</em>, <em>test_data_set: torch.utils.data.dataloader.DataLoader = None</em>, <em>epochs: int = 3</em>, <em>batch_size: int = 8</em>, <em>optimizer=None</em>, <em>max_grad_norm: float = 5.0</em>, <em>logging_steps: int = 50</em>, <em>save_steps: int = 100</em>, <em>save_path: str = None</em>, <em>distiller: nlp_architect.nn.torch.distillation.TeacherStudentDistill = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.train" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train a tagging model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_data_set</strong> (<em>DataLoader</em>) â train examples dataloader. If distiller object is</li>
<li><strong>train examples should contain a tuple of student/teacher data examples.</strong> (<em>provided</em>) â </li>
<li><strong>dev_data_set</strong> (<em>DataLoader</em><em>, </em><em>optional</em>) â dev examples dataloader. Defaults to None.</li>
<li><strong>test_data_set</strong> (<em>DataLoader</em><em>, </em><em>optional</em>) â test examples dataloader. Defaults to None.</li>
<li><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) â num of epochs to train. Defaults to 3.</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) â batch size. Defaults to 8.</li>
<li><strong>optimizer</strong> (<em>fn</em><em>, </em><em>optional</em>) â optimizer function. Defaults to default model optimizer.</li>
<li><strong>max_grad_norm</strong> (<em>float</em><em>, </em><em>optional</em>) â max gradient norm. Defaults to 5.0.</li>
<li><strong>logging_steps</strong> (<em>int</em><em>, </em><em>optional</em>) â number of steps between logging. Defaults to 50.</li>
<li><strong>save_steps</strong> (<em>int</em><em>, </em><em>optional</em>) â number of steps between model saves. Defaults to 100.</li>
<li><strong>save_path</strong> (<em>str</em><em>, </em><em>optional</em>) â model output path. Defaults to None.</li>
<li><strong>distiller</strong> (<a class="reference internal" href="../transformers_distillation.html#nlp_architect.nn.torch.distillation.TeacherStudentDistill" title="nlp_architect.nn.torch.distillation.TeacherStudentDistill"><em>TeacherStudentDistill</em></a><em>, </em><em>optional</em>) â KD model for training the model using</li>
<li><strong>teacher model. Defaults to None.</strong> (<em>a</em>) â </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.tagging.NeuralTagger.train_pseudo">
<code class="descname">train_pseudo</code><span class="sig-paren">(</span><em>labeled_data_set: torch.utils.data.dataloader.DataLoader</em>, <em>unlabeled_data_set: torch.utils.data.dataloader.DataLoader</em>, <em>distiller: nlp_architect.nn.torch.distillation.TeacherStudentDistill</em>, <em>dev_data_set: torch.utils.data.dataloader.DataLoader = None</em>, <em>test_data_set: torch.utils.data.dataloader.DataLoader = None</em>, <em>batch_size_l: int = 8</em>, <em>batch_size_ul: int = 8</em>, <em>epochs: int = 100</em>, <em>optimizer=None</em>, <em>max_grad_norm: float = 5.0</em>, <em>logging_steps: int = 50</em>, <em>save_steps: int = 100</em>, <em>save_path: str = None</em>, <em>save_best: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/tagging.html#NeuralTagger.train_pseudo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.tagging.NeuralTagger.train_pseudo" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Train a tagging model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_data_set</strong> (<em>DataLoader</em>) â train examples dataloader. If distiller object is</li>
<li><strong>train examples should contain a tuple of student/teacher data examples.</strong> (<em>provided</em>) â </li>
<li><strong>dev_data_set</strong> (<em>DataLoader</em><em>, </em><em>optional</em>) â dev examples dataloader. Defaults to None.</li>
<li><strong>test_data_set</strong> (<em>DataLoader</em><em>, </em><em>optional</em>) â test examples dataloader. Defaults to None.</li>
<li><strong>batch_size_l</strong> (<em>int</em><em>, </em><em>optional</em>) â batch size for the labeled dataset. Defaults to 8.</li>
<li><strong>batch_size_ul</strong> (<em>int</em><em>, </em><em>optional</em>) â batch size for the unlabeled dataset. Defaults to 8.</li>
<li><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) â num of epochs to train. Defaults to 100.</li>
<li><strong>optimizer</strong> (<em>fn</em><em>, </em><em>optional</em>) â optimizer function. Defaults to default model optimizer.</li>
<li><strong>max_grad_norm</strong> (<em>float</em><em>, </em><em>optional</em>) â max gradient norm. Defaults to 5.0.</li>
<li><strong>logging_steps</strong> (<em>int</em><em>, </em><em>optional</em>) â number of steps between logging. Defaults to 50.</li>
<li><strong>save_steps</strong> (<em>int</em><em>, </em><em>optional</em>) â number of steps between model saves. Defaults to 100.</li>
<li><strong>save_path</strong> (<em>str</em><em>, </em><em>optional</em>) â model output path. Defaults to None.</li>
<li><strong>save_best</strong> (<em>str</em><em>, </em><em>optional</em>) â wether to save model when result is best on dev set</li>
<li><strong>distiller</strong> (<a class="reference internal" href="../transformers_distillation.html#nlp_architect.nn.torch.distillation.TeacherStudentDistill" title="nlp_architect.nn.torch.distillation.TeacherStudentDistill"><em>TeacherStudentDistill</em></a><em>, </em><em>optional</em>) â KD model for training the model using</li>
<li><strong>teacher model. Defaults to None.</strong> (<em>a</em>) â </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models.temporal_convolutional_network">
<span id="nlp-architect-models-temporal-convolutional-network-module"></span><h2>nlp_architect.models.temporal_convolutional_network module<a class="headerlink" href="#module-nlp_architect.models.temporal_convolutional_network" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.temporal_convolutional_network.CommonLayers">
<em class="property">class </em><code class="descclassname">nlp_architect.models.temporal_convolutional_network.</code><code class="descname">CommonLayers</code><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#CommonLayers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.CommonLayers" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="docutils">
<dt>Class that contains the common layers for language modeling -</dt>
<dd>word embeddings and projection layer</dd>
</dl>
<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.CommonLayers.define_input_layer">
<code class="descname">define_input_layer</code><span class="sig-paren">(</span><em>input_placeholder_tokens</em>, <em>word_embeddings</em>, <em>embeddings_trainable=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#CommonLayers.define_input_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.CommonLayers.define_input_layer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Define the input word embedding layer
:param input_placeholder_tokens: tf.placeholder, input to the model
:param word_embeddings: numpy array (optional), to initialize the embeddings with
:param embeddings_trainable: boolean, whether or not to train the embedding table</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Embeddings corresponding to the data in input placeholder</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.CommonLayers.define_projection_layer">
<code class="descname">define_projection_layer</code><span class="sig-paren">(</span><em>prediction</em>, <em>tied_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#CommonLayers.define_projection_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.CommonLayers.define_projection_layer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Define the output word embedding layer
:param prediction: tf.tensor, the prediction from the model
:param tied_weights: boolean, whether or not to tie weights from the input embedding layer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Probability distribution over vocabulary</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.temporal_convolutional_network.TCN">
<em class="property">class </em><code class="descclassname">nlp_architect.models.temporal_convolutional_network.</code><code class="descname">TCN</code><span class="sig-paren">(</span><em>max_len</em>, <em>n_features_in</em>, <em>hidden_sizes</em>, <em>kernel_size=7</em>, <em>dropout=0.2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#TCN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.TCN" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class defines core TCN architecture.
This is only the base class, training strategy is not implemented.</p>
<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.TCN.build_network_graph">
<code class="descname">build_network_graph</code><span class="sig-paren">(</span><em>x</em>, <em>last_timepoint=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#TCN.build_network_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.TCN.build_network_graph" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Given the input placeholder x, build the entire TCN graph
:param x: Input placeholder
:param last_timepoint: Whether or not to select only the last timepoint to output</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">output of the TCN</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.TCN.build_train_graph">
<code class="descname">build_train_graph</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#TCN.build_train_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.TCN.build_train_graph" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Placeholder for defining training losses and metrics</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.TCN.calculate_receptive_field">
<code class="descname">calculate_receptive_field</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#TCN.calculate_receptive_field"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.TCN.calculate_receptive_field" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.TCN.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#TCN.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.TCN.run" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Placeholder for defining training strategy</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp_architect.models.temporal_convolutional_network.WeightNorm">
<em class="property">class </em><code class="descclassname">nlp_architect.models.temporal_convolutional_network.</code><code class="descname">WeightNorm</code><span class="sig-paren">(</span><em>layer</em>, <em>data_init=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#WeightNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.WeightNorm" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.wrappers.Wrapper</span></code></p>
<p>This wrapper reparameterizes a layer by decoupling the weightâs
magnitude and direction. This speeds up convergence by improving the
conditioning of the optimization problem.</p>
<p>Weight Normalization: A Simple Reparameterization to Accelerate
Training of Deep Neural Networks: <a class="reference external" href="https://arxiv.org/abs/1602.07868">https://arxiv.org/abs/1602.07868</a>
Tim Salimans, Diederik P. Kingma (2016)</p>
<p>WeightNorm wrapper works for keras and tf layers.</p>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python</dt>
<dd><dl class="first last docutils">
<dt>net = WeightNorm(tf.keras.layers.Conv2D(2, 2, activation=âreluâ),</dt>
<dd>input_shape=(32, 32, 3), data_init=True)(x)</dd>
<dt>net = WeightNorm(tf.keras.layers.Conv2D(16, 5, activation=âreluâ),</dt>
<dd>data_init=True)</dd>
<dt>net = WeightNorm(tf.keras.layers.Dense(120, activation=âreluâ),</dt>
<dd>data_init=True)(net)</dd>
<dt>net = WeightNorm(tf.keras.layers.Dense(n_classes),</dt>
<dd>data_init=True)(net)</dd>
</dl>
</dd>
</dl>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layer</strong> â a layer instance.</li>
<li><strong>data_init</strong> â If <cite>True</cite> use data dependent variable initialization</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code> â If not initialized with a <cite>Layer</cite> instance.</li>
<li><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code> â If <cite>Layer</cite> does not contain a <cite>kernel</cite> of weights</li>
<li><code class="xref py py-exc docutils literal notranslate"><span class="pre">NotImplementedError</span></code> â If <cite>data_init</cite> is True and running graph execution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.WeightNorm.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#WeightNorm.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.WeightNorm.build" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build <cite>Layer</cite></p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.WeightNorm.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>inputs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#WeightNorm.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.WeightNorm.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Call <cite>Layer</cite></p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.temporal_convolutional_network.WeightNorm.compute_output_shape">
<code class="descname">compute_output_shape</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models/temporal_convolutional_network.html#WeightNorm.compute_output_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.temporal_convolutional_network.WeightNorm.compute_output_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Computes the output shape of the layer.</p>
<p>If the layer has not been built, this method will call <cite>build</cite> on the
layer. This assumes that the layer will later be used with inputs that
match the input shape provided here.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_shape</strong> â Shape tuple (tuple of integers)
or list of shape tuples (one per output tensor of the layer).
Shape tuples can include None for free dimensions,
instead of an integer.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An input shape tuple.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp_architect.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-nlp_architect.models" title="Permalink to this headline">Â¶</a></h2>
<dl class="class">
<dt id="nlp_architect.models.TrainableModel">
<em class="property">class </em><code class="descclassname">nlp_architect.models.</code><code class="descname">TrainableModel</code><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for a trainable model</p>
<dl class="method">
<dt id="nlp_architect.models.TrainableModel.convert_to_tensors">
<code class="descname">convert_to_tensors</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.convert_to_tensors"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.convert_to_tensors" title="Permalink to this definition">Â¶</a></dt>
<dd><p>convert any chosen input to valid model format of tensors</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.TrainableModel.get_logits">
<code class="descname">get_logits</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.get_logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.get_logits" title="Permalink to this definition">Â¶</a></dt>
<dd><p>get model logits from given input</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.TrainableModel.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.inference" title="Permalink to this definition">Â¶</a></dt>
<dd><p>run inference</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.TrainableModel.load_model">
<code class="descname">load_model</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.load_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.load_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>load a model</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.TrainableModel.save_model">
<code class="descname">save_model</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.save_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.save_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>save the model</p>
</dd></dl>

<dl class="method">
<dt id="nlp_architect.models.TrainableModel.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nlp_architect/models.html#TrainableModel.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nlp_architect.models.TrainableModel.train" title="Permalink to this definition">Â¶</a></dt>
<dd><p>train the model</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>