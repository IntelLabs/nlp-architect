

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorflow.python.keras.callbacks &mdash; NLP Architect by Intel® AI Lab 0.4.post2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html">
          

          
            
            <img src="../../../../_static/nlp_architect_logo_white.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../main.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials.html">Jupyter Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../developer_guide.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../service.html">REST Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">Model Zoo</a></li>
</ul>
<p class="caption"><span class="caption-text">NLP/NLU Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../absa.html">Aspect Based Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chunker.html">Sequence Chunker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ner_crf.html">Named Entity Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../intent.html">Intent Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../np_segmentation.html">Noun Phrase Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bist_parser.html">BIST Dependency Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../word_sense.html">Most Common Word Sense</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../np2vec.html">Noun Phrase to Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../supervised_sentiment.html">Supervised Sentiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../reading_comprehension.html">Reading Comprehension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../memn2n.html">End-to-End Memory Networks for Goal Oriented Dialogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tcn.html">TCN Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../crosslingual_emb.html">Unsupervised Crosslingual Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cross_doc_coref.html">Cross Document Co-Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../identifying_semantic_relation.html">Semantic Relation Identification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse_gnmt.html">Sparse Neural Machine Translation</a></li>
</ul>
<p class="caption"><span class="caption-text">Solutions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../absa_solution.html">Aspect Based Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../term_set_expansion.html">Set Expansion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../trend_analysis.html">Trend Analysis</a></li>
</ul>
<p class="caption"><span class="caption-text">Pipelines</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../spacy_bist.html">Spacy-BIST Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../spacy_np_annotator.html">Spacy-NP Annotator</a></li>
</ul>
<p class="caption"><span class="caption-text">For Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api.html">API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">NLP Architect by Intel® AI Lab</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>tensorflow.python.keras.callbacks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tensorflow.python.keras.callbacks</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># pylint: disable=g-import-not-at-top</span>
<span class="sd">&quot;&quot;&quot;Callbacks: utilities called at certain points during model training.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">six</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.data.ops</span> <span class="k">import</span> <span class="n">iterator_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.distribute</span> <span class="k">import</span> <span class="n">distribute_coordinator_context</span> <span class="k">as</span> <span class="n">dc_context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.data_utils</span> <span class="k">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.generic_utils</span> <span class="k">import</span> <span class="n">Progbar</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.mode_keys</span> <span class="k">import</span> <span class="n">ModeKeys</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">summary_ops_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="k">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.training</span> <span class="k">import</span> <span class="n">checkpoint_management</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="k">import</span> <span class="n">keras_export</span>

<span class="k">try</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">requests</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
  <span class="n">requests</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># Constant for `tf.keras.Model` to store the epoch at which the most recently</span>
<span class="c1"># saved checkpoint was saved. See `Model._get_updated_initial_epoch()`&#39;s</span>
<span class="c1"># docstring for more information.</span>
<span class="n">CKPT_SAVED_EPOCH</span> <span class="o">=</span> <span class="s1">&#39;_ckpt_saved_epoch&#39;</span>


<span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span>
                        <span class="n">model</span><span class="p">,</span>
                        <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Configures callbacks for use in various training loops.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callbacks: List of Callbacks.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      count_mode: One of &#39;steps&#39; or &#39;samples&#39;. Per-batch or per-sample count.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>

<span class="sd">  Returns:</span>
<span class="sd">      Instance of CallbackList used to control all Callbacks.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Check if callbacks have already been configured.</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">callbacks</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">callbacks</span><span class="p">:</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Add additional callbacks during training.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseLogger</span><span class="p">()]</span> <span class="o">+</span> <span class="p">(</span><span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
      <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
  <span class="n">callback_list</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="c1"># Set callback model</span>
  <span class="n">callback_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_callback_model</span><span class="p">()</span>  <span class="c1"># pylint: disable=protected-access</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">callback_model</span><span class="p">)</span>

  <span class="n">set_callback_parameters</span><span class="p">(</span>
      <span class="n">callback_list</span><span class="p">,</span>
      <span class="n">model</span><span class="p">,</span>
      <span class="n">do_validation</span><span class="o">=</span><span class="n">do_validation</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
      <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
      <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
      <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>

  <span class="n">callback_list</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="c1"># pylint: disable=protected-access</span>
  <span class="k">if</span> <span class="n">callback_list</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># The attribute `_ckpt_saved_epoch` is supposed to be None at the start of</span>
    <span class="c1"># training (it should be made None at the end of successful multi-worker</span>
    <span class="c1"># training), unless the user&#39;s `fit()` does not end successfully before</span>
    <span class="c1"># making another `fit()` call.</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s1">&#39;`tf.Keras.Model._ckpt_saved_epoch` attr should be None at &#39;</span>
        <span class="s1">&#39;callback setup time. Please ensure `fit()` in multi-worker &#39;</span>
        <span class="s1">&#39;training finishes successfully before starting a new one. If the &#39;</span>
        <span class="s1">&#39;issue persists, try using only one `model.fit()` in multi-worker &#39;</span>
        <span class="s1">&#39;training.&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">callback_list</span>


<span class="k">def</span> <span class="nf">set_callback_parameters</span><span class="p">(</span><span class="n">callback_list</span><span class="p">,</span>
                            <span class="n">model</span><span class="p">,</span>
                            <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Sets callback parameters.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callback_list: CallbackList instance.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="n">callback_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cbk</span><span class="p">,</span> <span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">)):</span>
      <span class="n">cbk</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Exclude `loss`</span>

  <span class="c1"># Set callback parameters</span>
  <span class="n">callback_metrics</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="c1"># When we have deferred build scenario with iterator input, we will compile</span>
  <span class="c1"># when we standardize first batch of data.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;metrics_names&#39;</span><span class="p">):</span>
    <span class="n">callback_metrics</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">do_validation</span><span class="p">:</span>
      <span class="n">callback_metrics</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">]</span>
  <span class="n">callback_params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
      <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="s1">&#39;samples&#39;</span><span class="p">:</span> <span class="n">samples</span><span class="p">,</span>
      <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="n">verbose</span><span class="p">,</span>
      <span class="s1">&#39;do_validation&#39;</span><span class="p">:</span> <span class="n">do_validation</span><span class="p">,</span>
      <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="n">callback_metrics</span><span class="p">,</span>
  <span class="p">}</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">callback_params</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_generator_like</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Checks if data is a generator, Sequence, or Iterator.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;next&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__next__&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">IteratorV2</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">make_logs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes logs for sending to `on_batch_end` methods.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">{</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">}:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;metrics_names&#39;</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">logs</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
  <span class="k">return</span> <span class="n">logs</span>


<span class="k">class</span> <span class="nc">CallbackList</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container abstracting a list of callbacks.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callbacks: List of `Callback` instances.</span>
<span class="sd">      queue_length: Queue length for keeping</span>
<span class="sd">          running statistics over callback execution time.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">queue_length</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">queue_length</span> <span class="o">=</span> <span class="n">queue_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_batch_timing</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_reset_batch_timing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span>
        <span class="k">lambda</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">([],</span> <span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">queue_length</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_batch_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for all batch_{begin | end} methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="n">hook_name</span> <span class="o">=</span> <span class="s1">&#39;on_</span><span class="si">{mode}</span><span class="s1">_batch_</span><span class="si">{hook}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="o">=</span><span class="n">hook</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;begin&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_t_enter_batch</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;end&#39;</span><span class="p">:</span>
      <span class="c1"># Batch is ending, calculate batch time.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_t_enter_batch</span>

    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">t_before_callbacks</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">batch_hook</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
      <span class="n">batch_hook</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_before_callbacks</span><span class="p">)</span>

    <span class="n">delta_t_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span><span class="p">[</span><span class="n">hook_name</span><span class="p">])</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">&gt;</span> <span class="mf">0.</span> <span class="ow">and</span>
        <span class="n">delta_t_median</span> <span class="o">&gt;</span> <span class="mf">0.95</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="ow">and</span> <span class="n">delta_t_median</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
          <span class="s1">&#39;Method (</span><span class="si">%s</span><span class="s1">) is slow compared &#39;</span>
          <span class="s1">&#39;to the batch update (</span><span class="si">%f</span><span class="s1">). Check your callbacks.&#39;</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span>
          <span class="n">delta_t_median</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_begin methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_call_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_end methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_begin` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_batch_timing</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_end` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the &#39;on_predict_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.Callback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Callback</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Abstract base class used to build new callbacks.</span>

<span class="sd">  Attributes:</span>
<span class="sd">      params: dict. Training parameters</span>
<span class="sd">          (eg. verbosity, batch size, number of epochs...).</span>
<span class="sd">      model: instance of `keras.models.Model`.</span>
<span class="sd">          Reference of the model being trained.</span>
<span class="sd">      validation_data: Deprecated. Do not use.</span>

<span class="sd">  The `logs` dictionary that callback methods</span>
<span class="sd">  take as argument will contain keys for quantities relevant to</span>
<span class="sd">  the current batch or epoch.</span>

<span class="sd">  Currently, the `.fit()` method of the `Model` class</span>
<span class="sd">  will include the following quantities in the `logs` that</span>
<span class="sd">  it passes to its callbacks:</span>

<span class="sd">      on_epoch_end: logs include `acc` and `loss`, and</span>
<span class="sd">          optionally include `val_loss`</span>
<span class="sd">          (if validation is enabled in `fit`), and `val_acc`</span>
<span class="sd">          (if validation and accuracy monitoring are enabled).</span>
<span class="sd">      on_batch_begin: logs include `size`,</span>
<span class="sd">          the number of samples in the current batch.</span>
<span class="sd">      on_batch_end: logs include `loss`, and optionally `acc`</span>
<span class="sd">          (if accuracy monitoring is enabled).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Whether this Callback should only run on the chief worker in a</span>
    <span class="c1"># Multi-Worker setting.</span>
    <span class="c1"># TODO(omalleyt): Make this attr public once solution is stable.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_begin`.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_end`.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the start of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the beginning of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the end of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.BaseLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BaseLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that accumulates epoch averages of metrics.</span>

<span class="sd">  This callback is automatically applied to every Keras model.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is in `on_epoch_end`.</span>
<span class="sd">          All others will be averaged in `on_epoch_end`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">totals</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
    <span class="c1"># at the same time, we should account for that in the `seen` calculation.</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="c1"># Make value available to next callbacks.</span>
          <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TerminateOnNaN&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TerminateOnNaN</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that terminates training when a NaN loss is encountered.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Batch </span><span class="si">%d</span><span class="s1">: Invalid loss, terminating training&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ProgbarLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ProgbarLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that prints metrics to stdout.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      count_mode: One of &quot;steps&quot; or &quot;samples&quot;.</span>
<span class="sd">          Whether the progress bar should</span>
<span class="sd">          count samples seen or steps (batches) seen.</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is.</span>
<span class="sd">          All others will be averaged over time (e.g. loss, etc).</span>

<span class="sd">  Raises:</span>
<span class="sd">      ValueError: In case of invalid `count_mode`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;samples&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;steps&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown `count_mode`: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;verbose&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;samples&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="n">Progbar</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">stateful_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">,</span>
        <span class="n">unit_name</span><span class="o">=</span><span class="s1">&#39;step&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="k">else</span> <span class="s1">&#39;sample&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
    <span class="c1"># at the same time, we should account for that in the `seen` calculation.</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">num_steps</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>

    <span class="c1"># Skip progbar update for the last batch;</span>
    <span class="c1"># will be handled by on_epoch_end.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.History&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">History</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that records events into a `History` object.</span>

<span class="sd">  This callback is automatically applied to</span>
<span class="sd">  every Keras model. The `History` object</span>
<span class="sd">  gets returned by the `fit` method of models.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ModelCheckpoint&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Save the model after every epoch.</span>

<span class="sd">  `filepath` can contain named formatting options,</span>
<span class="sd">  which will be filled the value of `epoch` and</span>
<span class="sd">  keys in `logs` (passed in `on_epoch_end`).</span>

<span class="sd">  For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,</span>
<span class="sd">  then the model checkpoints will be saved with the epoch number and</span>
<span class="sd">  the validation loss in the filename.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      filepath: string, path to save the model file.</span>
<span class="sd">      monitor: quantity to monitor.</span>
<span class="sd">      verbose: verbosity mode, 0 or 1.</span>
<span class="sd">      save_best_only: if `save_best_only=True`, the latest best model according</span>
<span class="sd">        to the quantity monitored will not be overwritten.</span>
<span class="sd">      mode: one of {auto, min, max}. If `save_best_only=True`, the decision to</span>
<span class="sd">        overwrite the current save file is made based on either the maximization</span>
<span class="sd">        or the minimization of the monitored quantity. For `val_acc`, this</span>
<span class="sd">        should be `max`, for `val_loss` this should be `min`, etc. In `auto`</span>
<span class="sd">        mode, the direction is automatically inferred from the name of the</span>
<span class="sd">        monitored quantity.</span>
<span class="sd">      save_weights_only: if True, then only the model&#39;s weights will be saved</span>
<span class="sd">        (`model.save_weights(filepath)`), else the full model is saved</span>
<span class="sd">        (`model.save(filepath)`).</span>
<span class="sd">      save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback saves</span>
<span class="sd">        the model after each epoch. When using integer, the callback saves the</span>
<span class="sd">        model at end of a batch at which this many samples have been seen since</span>
<span class="sd">        last saving. Note that if the saving isn&#39;t aligned to epochs, the</span>
<span class="sd">        monitored metric may potentially be less reliable (it could reflect as</span>
<span class="sd">        little as 1 batch, since the metrics get reset every epoch). Defaults to</span>
<span class="sd">        `&#39;epoch&#39;`</span>
<span class="sd">      load_weights_on_restart: Whether the training should restore the model. If</span>
<span class="sd">        True, the model will attempt to load the checkpoint file from `filepath`</span>
<span class="sd">        at the start of `model.fit()`. This saves the need of manually calling</span>
<span class="sd">        `model.load_weights()` before `model.fit(). In multi-worker distributed</span>
<span class="sd">        training, this provides fault-tolerance and loads the model</span>
<span class="sd">        automatically upon recovery of workers. The callback gives up loading if</span>
<span class="sd">        the filepath does not exist, and raises ValueError if format does not</span>
<span class="sd">        match. Defaults to False.</span>
<span class="sd">      **kwargs: Additional arguments for backwards compatibility. Possible key</span>
<span class="sd">        is `period`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">filepath</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">save_best_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">save_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="n">load_weights_on_restart</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">filepath</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span> <span class="o">=</span> <span class="n">save_best_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="n">save_weights_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="n">load_weights_on_restart</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Deprecated field `period` is for the number of epochs between which</span>
    <span class="c1"># the model is saved.</span>
    <span class="k">if</span> <span class="s1">&#39;period&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;period&#39;</span><span class="p">]</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`period` argument is deprecated. Please use `save_freq` &#39;</span>
                      <span class="s1">&#39;to specify the frequency in number of samples seen.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;ModelCheckpoint mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;fmeasure&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized save_freq: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">))</span>

    <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
    <span class="c1"># restore checkpoint at on_train_begin().</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="c1"># Use name matching rather than `isinstance` to avoid circular dependencies.</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># TODO(rchao): Replace dc_context reference with</span>
    <span class="c1"># distributed_training_utils.should_current_worker_load_model() once</span>
    <span class="c1"># distributed_training_utils.py no longer depends on callbacks.py.</span>
    <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">in_multi_worker_mode</span><span class="p">(</span>
    <span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">dc_context</span><span class="o">.</span><span class="n">get_current_worker_context</span><span class="p">()</span><span class="o">.</span><span class="n">experimental_should_init</span><span class="p">:</span>
      <span class="c1"># For multi-worker training, it should not restore a model in certain</span>
      <span class="c1"># worker setting (e.g. non-chief worker in ParameterServerStrategy).</span>
      <span class="k">return</span>

    <span class="n">filepath_to_load</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="ow">and</span> <span class="n">filepath_to_load</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="c1"># `filepath` may contain placeholders such as `{epoch:02d}`, and thus</span>
        <span class="c1"># it attempts to load the most recently modified file with file name</span>
        <span class="c1"># matching the pattern.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">IOError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Error loading file from </span><span class="si">{}</span><span class="s1">. Reason: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">filepath_to_load</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Make `_ckpt_saved_epoch` attribute `None` at the end of training as it</span>
      <span class="c1"># is only used during the training. Currently it is decided not to</span>
      <span class="c1"># support fault tolerance across multiple `model.fit()` or `model.fit()`</span>
      <span class="c1"># with other `model` methods.</span>
      <span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="c1"># TODO(rchao): Support all `save_weights_only` and `save_best_only` cases.</span>
      <span class="c1"># This will be done with the help of a decoupled training state file that</span>
      <span class="c1"># contains both epoch and model weights.</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span><span class="p">:</span>
        <span class="n">file_handle</span><span class="p">,</span> <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_handle_and_path</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_remove_file</span><span class="p">(</span><span class="n">file_handle</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">+=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Saves the model.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: the epoch this iteration is in.</span>
<span class="sd">        logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span>
                  <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">file_handle</span><span class="p">,</span> <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_handle_and_path</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span><span class="p">:</span>
        <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Can save best model only with </span><span class="si">%s</span><span class="s1"> available, &#39;</span>
                          <span class="s1">&#39;skipping.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> improved from </span><span class="si">%0.5f</span><span class="s1"> to </span><span class="si">%0.5f</span><span class="s1">,&#39;</span>
                    <span class="s1">&#39; saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">,</span>
                                             <span class="n">current</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> did not improve from </span><span class="si">%0.5f</span><span class="s1">&#39;</span> <span class="o">%</span>
                    <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">in_multi_worker_mode</span><span class="p">():</span>
            <span class="c1"># TODO(rchao): Save to an additional training state file for FT,</span>
            <span class="c1"># instead of adding an attr to weight file. With this we can support</span>
            <span class="c1"># the cases of all combinations with `save_weights_only`,</span>
            <span class="c1"># `save_best_only`, and `save_format` parameters.</span>
            <span class="c1"># pylint: disable=protected-access</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_ckpt_saved_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_remove_file</span><span class="p">(</span><span class="n">file_handle</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_get_file_handle_and_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the file handle and path.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(rchao): Replace dc_context reference with</span>
    <span class="c1"># distributed_training_utils.should_current_worker_checkpoint() once</span>
    <span class="c1"># distributed_training_utils.py no longer depends on callbacks.py.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">K</span><span class="o">.</span><span class="n">in_multi_worker_mode</span><span class="p">()</span> <span class="ow">or</span> <span class="n">dc_context</span><span class="o">.</span><span class="n">get_current_worker_context</span><span class="p">(</span>
    <span class="p">)</span><span class="o">.</span><span class="n">should_checkpoint</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If this is multi-worker training, and this worker should not</span>
      <span class="c1"># save checkpoint, we replace the filepath with a dummy filepath so</span>
      <span class="c1"># it writes to a file that will be removed at the end of _save_model()</span>
      <span class="c1"># call. This is because the SyncOnReadVariable needs to be synced across</span>
      <span class="c1"># all the workers in order to be read, and all workers need to initiate</span>
      <span class="c1"># that.</span>
      <span class="n">file_handle</span><span class="p">,</span> <span class="n">temp_file_name</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkstemp</span><span class="p">()</span>
      <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">file_handle</span><span class="p">,</span> <span class="n">temp_file_name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">extension</span>

  <span class="k">def</span> <span class="nf">_maybe_remove_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_handle</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
    <span class="c1"># Remove the file in multi-worker training where this worker should</span>
    <span class="c1"># not checkpoint. It is a dummy file previously saved for sync distributed</span>
    <span class="c1"># training.</span>
    <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">in_multi_worker_mode</span><span class="p">(</span>
    <span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">dc_context</span><span class="o">.</span><span class="n">get_current_worker_context</span><span class="p">()</span><span class="o">.</span><span class="n">should_checkpoint</span><span class="p">:</span>
      <span class="n">os</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">file_handle</span><span class="p">)</span>
      <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the most recently modified filepath matching pattern.</span>

<span class="sd">    Pattern may contain python formatting placeholder. If</span>
<span class="sd">    `tf.train.latest_checkpoint()` does not return None, use that; otherwise,</span>
<span class="sd">    check for most recently modified one that matches the pattern.</span>

<span class="sd">    In the rare case where there are more than one pattern-matching file having</span>
<span class="sd">    the same modified time that is most recent among all, return the filepath</span>
<span class="sd">    that is largest (by `&gt;` operator, lexicographically using the numeric</span>
<span class="sd">    equivalents). This provides a tie-breaker when multiple files are most</span>
<span class="sd">    recent. Note that a larger `filepath` can sometimes indicate a later time of</span>
<span class="sd">    modification (for instance, when epoch/batch is used as formatting option),</span>
<span class="sd">    but not necessarily (when accuracy or loss is used). The tie-breaker is</span>
<span class="sd">    put in the logic as best effort to return the most recent, and to avoid</span>
<span class="sd">    undeterministic result.</span>

<span class="sd">    Modified time of a file is obtained with `os.path.getmtime()`.</span>

<span class="sd">    This utility function is best demonstrated via an example:</span>

<span class="sd">    ```python</span>
<span class="sd">    file_pattern = &#39;f.batch{batch:02d}epoch{epoch:02d}.h5&#39;</span>
<span class="sd">    test_dir = self.get_temp_dir()</span>
<span class="sd">    path_pattern = os.path.join(test_dir, file_pattern)</span>
<span class="sd">    file_paths = [</span>
<span class="sd">        os.path.join(test_dir, file_name) for file_name in</span>
<span class="sd">        [&#39;f.batch03epoch02.h5&#39;, &#39;f.batch02epoch02.h5&#39;, &#39;f.batch01epoch01.h5&#39;]</span>
<span class="sd">    ]</span>
<span class="sd">    for file_path in file_paths:</span>
<span class="sd">      # Write something to each of the files</span>
<span class="sd">    self.assertEqual(</span>
<span class="sd">        _get_most_recently_modified_file_matching_pattern(path_pattern),</span>
<span class="sd">        file_paths[-1])</span>
<span class="sd">    ```</span>

<span class="sd">    Arguments:</span>
<span class="sd">        pattern: The file pattern that may optionally contain python placeholder</span>
<span class="sd">            such as `{epoch:02d}`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The most recently modified file&#39;s full filepath matching `pattern`. If</span>
<span class="sd">        `pattern` does not contain any placeholder, this returns the filepath</span>
<span class="sd">        that</span>
<span class="sd">        exactly matches `pattern`. Returns `None` if no match is found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name_regex</span> <span class="o">=</span> <span class="s1">&#39;^&#39;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;{.*}&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;.*&#39;</span><span class="p">,</span> <span class="n">base_name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;$&#39;</span>

    <span class="c1"># If tf.train.latest_checkpoint tells us there exists a latest checkpoint,</span>
    <span class="c1"># use that as it is more robust than `os.path.getmtime()`.</span>
    <span class="n">latest_tf_checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_management</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_tf_checkpoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
        <span class="n">base_name_regex</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">latest_tf_checkpoint</span><span class="p">)):</span>
      <span class="k">return</span> <span class="n">latest_tf_checkpoint</span>

    <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
        <span class="c1"># Only consider if `file_name` matches the pattern.</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">base_name_regex</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
          <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
          <span class="n">mod_time</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getmtime</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
          <span class="k">if</span> <span class="p">(</span><span class="n">file_path_with_largest_file_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
              <span class="n">file_path</span> <span class="o">&gt;</span> <span class="n">file_path_with_largest_file_name</span><span class="p">):</span>
            <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="n">file_path</span>
          <span class="k">if</span> <span class="n">mod_time</span> <span class="o">&gt;</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="n">mod_time</span>
            <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="n">file_path</span>
            <span class="c1"># In the case a file with later modified time is found, reset</span>
            <span class="c1"># the counter for the number of files with latest modified time.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">1</span>
          <span class="k">elif</span> <span class="n">mod_time</span> <span class="o">==</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="c1"># In the case a file has modified time tied with the most recent,</span>
            <span class="c1"># increment the counter for the number of files with latest modified</span>
            <span class="c1"># time by 1.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">n_file_with_latest_mod_time</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Return the sole file that has most recent modified time.</span>
      <span class="k">return</span> <span class="n">file_path_with_latest_mod_time</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If there are more than one file having latest modified time, return</span>
      <span class="c1"># the file path with the largest file name.</span>
      <span class="k">return</span> <span class="n">file_path_with_largest_file_name</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.EarlyStopping&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Stop training when a monitored quantity has stopped improving.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      monitor: Quantity to be monitored.</span>
<span class="sd">      min_delta: Minimum change in the monitored quantity</span>
<span class="sd">          to qualify as an improvement, i.e. an absolute</span>
<span class="sd">          change of less than min_delta, will count as no</span>
<span class="sd">          improvement.</span>
<span class="sd">      patience: Number of epochs with no improvement</span>
<span class="sd">          after which training will be stopped.</span>
<span class="sd">      verbose: verbosity mode.</span>
<span class="sd">      mode: One of `{&quot;auto&quot;, &quot;min&quot;, &quot;max&quot;}`. In `min` mode,</span>
<span class="sd">          training will stop when the quantity</span>
<span class="sd">          monitored has stopped decreasing; in `max`</span>
<span class="sd">          mode it will stop when the quantity</span>
<span class="sd">          monitored has stopped increasing; in `auto`</span>
<span class="sd">          mode, the direction is automatically inferred</span>
<span class="sd">          from the name of the monitored quantity.</span>
<span class="sd">      baseline: Baseline value for the monitored quantity.</span>
<span class="sd">          Training will stop if the model doesn&#39;t show improvement over the</span>
<span class="sd">          baseline.</span>
<span class="sd">      restore_best_weights: Whether to restore model weights from</span>
<span class="sd">          the epoch with the best value of the monitored quantity.</span>
<span class="sd">          If False, the model weights obtained at the last step of</span>
<span class="sd">          training are used.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, patience=3)</span>
<span class="sd">  # This callback will stop the training when there is no improvement in</span>
<span class="sd">  # the validation loss for three consecutive epochs.</span>
<span class="sd">  model.fit(data, labels, epochs=100, callbacks=[callback],</span>
<span class="sd">      validation_data=(val_data, val_labels))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EarlyStopping</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_delta</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="o">=</span> <span class="n">restore_best_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;EarlyStopping mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Allow instances to be re-used</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_monitor_value</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Restoring model weights from the end of the best epoch.&#39;</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%05d</span><span class="s1">: early stopping&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">get_monitor_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">monitor_value</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">monitor_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Early stopping conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">monitor_value</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.RemoteMonitor&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RemoteMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback used to stream events to a server.</span>

<span class="sd">  Requires the `requests` library.</span>
<span class="sd">  Events are sent to `root + &#39;/publish/epoch/end/&#39;` by default. Calls are</span>
<span class="sd">  HTTP POST, with a `data` argument which is a</span>
<span class="sd">  JSON-encoded dictionary of event data.</span>
<span class="sd">  If send_as_json is set to True, the content type of the request will be</span>
<span class="sd">  application/json. Otherwise the serialized JSON will be sent within a form.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      root: String; root url of the target server.</span>
<span class="sd">      path: String; path relative to `root` to which the events will be sent.</span>
<span class="sd">      field: String; JSON field under which the data will be stored.</span>
<span class="sd">          The field is used only if the payload is sent within a form</span>
<span class="sd">          (i.e. send_as_json is set to False).</span>
<span class="sd">      headers: Dictionary; optional custom HTTP headers.</span>
<span class="sd">      send_as_json: Boolean; whether the request should be</span>
<span class="sd">          sent as application/json.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">root</span><span class="o">=</span><span class="s1">&#39;http://localhost:9000&#39;</span><span class="p">,</span>
               <span class="n">path</span><span class="o">=</span><span class="s1">&#39;/publish/epoch/end/&#39;</span><span class="p">,</span>
               <span class="n">field</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span>
               <span class="n">headers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">send_as_json</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RemoteMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="n">field</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span> <span class="o">=</span> <span class="n">send_as_json</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">requests</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;RemoteMonitor requires the `requests` library.&#39;</span><span class="p">)</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">send</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">send</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">send</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">send</span><span class="p">)},</span>
            <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Warning: could not reach RemoteMonitor &#39;</span>
                      <span class="s1">&#39;root server at &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">))</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LearningRateScheduler&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LearningRateScheduler</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Learning rate scheduler.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      schedule: a function that takes an epoch index as input</span>
<span class="sd">          (integer, indexed from 0) and returns a new</span>
<span class="sd">          learning rate as output (float).</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>

<span class="sd">  ```python</span>
<span class="sd">  # This function keeps the learning rate at 0.001 for the first ten epochs</span>
<span class="sd">  # and decreases it exponentially after that.</span>
<span class="sd">  def scheduler(epoch):</span>
<span class="sd">    if epoch &lt; 10:</span>
<span class="sd">      return 0.001</span>
<span class="sd">    else:</span>
<span class="sd">      return 0.001 * tf.math.exp(0.1 * (10 - epoch))</span>

<span class="sd">  callback = tf.keras.callbacks.LearningRateScheduler(scheduler)</span>
<span class="sd">  model.fit(data, labels, epochs=100, callbacks=[callback],</span>
<span class="sd">            validation_data=(val_data, val_labels))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schedule</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LearningRateScheduler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">schedule</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Optimizer must have a &quot;lr&quot; attribute.&#39;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>  <span class="c1"># new API</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>  <span class="c1"># Support for old API for backward compatibility</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The output of the &quot;schedule&quot; function &#39;</span>
                       <span class="s1">&#39;should be float.&#39;</span><span class="p">)</span>
    <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: LearningRateScheduler reducing learning &#39;</span>
            <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TensorBoard&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">TensorBoard</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="c1"># pylint: disable=line-too-long</span>
  <span class="sd">&quot;&quot;&quot;Enable visualizations for TensorBoard.</span>

<span class="sd">  TensorBoard is a visualization tool provided with TensorFlow.</span>

<span class="sd">  This callback logs events for TensorBoard, including:</span>
<span class="sd">  * Metrics summary plots</span>
<span class="sd">  * Training graph visualization</span>
<span class="sd">  * Activation histograms</span>
<span class="sd">  * Sampled profiling</span>

<span class="sd">  If you have installed TensorFlow with pip, you should be able</span>
<span class="sd">  to launch TensorBoard from the command line:</span>

<span class="sd">  ```sh</span>
<span class="sd">  tensorboard --logdir=path_to_your_logs</span>
<span class="sd">  ```</span>

<span class="sd">  You can find more information about TensorBoard</span>
<span class="sd">  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).</span>

<span class="sd">  Arguments:</span>
<span class="sd">      log_dir: the path of the directory where to save the log files to be</span>
<span class="sd">        parsed by TensorBoard.</span>
<span class="sd">      histogram_freq: frequency (in epochs) at which to compute activation and</span>
<span class="sd">        weight histograms for the layers of the model. If set to 0, histograms</span>
<span class="sd">        won&#39;t be computed. Validation data (or split) must be specified for</span>
<span class="sd">        histogram visualizations.</span>
<span class="sd">      write_graph: whether to visualize the graph in TensorBoard. The log file</span>
<span class="sd">        can become quite large when write_graph is set to True.</span>
<span class="sd">      write_images: whether to write model weights to visualize as image in</span>
<span class="sd">        TensorBoard.</span>
<span class="sd">      update_freq: `&#39;batch&#39;` or `&#39;epoch&#39;` or integer. When using `&#39;batch&#39;`,</span>
<span class="sd">        writes the losses and metrics to TensorBoard after each batch. The same</span>
<span class="sd">        applies for `&#39;epoch&#39;`. If using an integer, let&#39;s say `1000`, the</span>
<span class="sd">        callback will write the metrics and losses to TensorBoard every 1000</span>
<span class="sd">        samples. Note that writing too frequently to TensorBoard can slow down</span>
<span class="sd">        your training.</span>
<span class="sd">      profile_batch: Profile the batch to sample compute characteristics. By</span>
<span class="sd">        default, it will profile the second batch. Set profile_batch=0 to</span>
<span class="sd">        disable profiling. Must run in TensorFlow eager mode.</span>
<span class="sd">      embeddings_freq: frequency (in epochs) at which embedding layers will</span>
<span class="sd">        be visualized. If set to 0, embeddings won&#39;t be visualized.</span>
<span class="sd">      embeddings_metadata: a dictionary which maps layer name to a file name in</span>
<span class="sd">        which metadata for this embedding layer is saved. See the</span>
<span class="sd">        [details](</span>
<span class="sd">          https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)</span>
<span class="sd">        about metadata files format. In case if the same metadata file is</span>
<span class="sd">        used for all embedding layers, string can be passed.</span>

<span class="sd">  Raises:</span>
<span class="sd">      ValueError: If histogram_freq is set and no validation data is provided.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># pylint: enable=line-too-long</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span>
               <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">write_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">write_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">update_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="n">profile_batch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">embeddings_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">embeddings_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TensorBoard</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">=</span> <span class="n">histogram_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span> <span class="o">=</span> <span class="n">write_graph</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span> <span class="o">=</span> <span class="n">write_images</span>
    <span class="k">if</span> <span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;batch&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="n">update_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">=</span> <span class="n">embeddings_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="o">=</span> <span class="n">embeddings_metadata</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_at_last_write</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_current_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_total_val_batches_seen</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># A collection of file writers currently in use, to be closed when</span>
    <span class="c1"># training ends for this callback. Writers are keyed by the</span>
    <span class="c1"># directory name under the root logdir: e.g., &quot;train&quot; or</span>
    <span class="c1"># &quot;validation&quot;.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span> <span class="o">=</span> <span class="s1">&#39;validation&#39;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
    <span class="c1"># True when a trace is running.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># TensorBoard should only write summaries on the chief when in a</span>
    <span class="c1"># Multi-Worker setting.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">_validate_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handle arguments were supported in V1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`write_grads` will be ignored in TensorFlow 2.0 &#39;</span>
                      <span class="s1">&#39;for the `TensorBoard` Callback.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`batch_size` is no longer needed in the &#39;</span>
                      <span class="s1">&#39;`TensorBoard` Callback and will be ignored &#39;</span>
                      <span class="s1">&#39;in TensorFlow 2.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_layer_names` is not supported in &#39;</span>
                      <span class="s1">&#39;TensorFlow 2.0. Instead, all `Embedding` layers &#39;</span>
                      <span class="s1">&#39;will be visualized.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_data` is not supported in TensorFlow &#39;</span>
                      <span class="s1">&#39;2.0. Instead, all `Embedding` variables will be &#39;</span>
                      <span class="s1">&#39;visualized.&#39;</span><span class="p">)</span>

    <span class="n">unrecognized_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="p">{</span>
        <span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Only allow kwargs that were supported in V1.</span>
    <span class="k">if</span> <span class="n">unrecognized_kwargs</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized arguments in `TensorBoard` &#39;</span>
                       <span class="s1">&#39;Callback: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">unrecognized_kwargs</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets Keras model and writes graph if specified.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span><span class="p">:</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
          <span class="k">with</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">summary_writable</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">or</span>  <span class="c1"># pylint: disable=protected-access</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
            <span class="k">if</span> <span class="n">summary_writable</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="s1">&#39;keras&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_configure_embeddings</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_configure_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configure the Projector for embeddings.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(omalleyt): Add integration tests.</span>
    <span class="kn">from</span> <span class="nn">tensorflow.python.keras.layers</span> <span class="k">import</span> <span class="n">embeddings</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="kn">from</span> <span class="nn">tensorboard.plugins</span> <span class="k">import</span> <span class="n">projector</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;Failed to import TensorBoard. Please make sure that &#39;</span>
                        <span class="s1">&#39;TensorBoard integration is complete.&quot;&#39;</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">projector</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">embedding</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">name</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span><span class="p">:</span>
              <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized `Embedding` layer names passed to &#39;</span>
                       <span class="s1">&#39;`keras.callbacks.TensorBoard` `embeddings_metadata` &#39;</span>
                       <span class="s1">&#39;argument: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="k">class</span> <span class="nc">DummyWriter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Dummy writer to conform to `Projector` API.&quot;&quot;&quot;</span>

      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logdir</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logdir</span> <span class="o">=</span> <span class="n">logdir</span>

      <span class="k">def</span> <span class="nf">get_logdir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">logdir</span>

    <span class="n">writer</span> <span class="o">=</span> <span class="n">DummyWriter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
    <span class="n">projector</span><span class="o">.</span><span class="n">visualize_embeddings</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_close_writers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Close all remaining open file writers owned by this callback.</span>

<span class="sd">    If there are no such file writers, this is a no-op.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">writer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">itervalues</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">):</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a summary writer for the given subdirectory under the logdir.</span>

<span class="sd">    A writer will be created if it does not yet exist.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      writer_name: The name of the directory for which to create or</span>
<span class="sd">        retrieve a writer. Should be either `self._train_run_name` or</span>
<span class="sd">        `self._validation_run_name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `SummaryWriter` object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">writer_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
      <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">)</span>
      <span class="n">writer</span> <span class="o">=</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">create_file_writer_v2</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">writer</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes scalar summaries for metrics on every training batch.</span>

<span class="sd">    Performs profiling if current batch is in profiler_batches.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      batch: Integer, index of batch within the current epoch.</span>
<span class="sd">      logs: Dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Don&#39;t output batch_size and batch number as TensorBoard summaries</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span> <span class="o">+=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">samples_seen_since</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_at_last_write</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="n">samples_seen_since</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;batch_&#39;</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_at_last_write</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_trace</span><span class="p">()</span>
    <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="ow">and</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_enable_trace</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs metrics and histogram summaries at epoch end.&quot;&quot;&quot;</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">epoch</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;epoch_&#39;</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_weights</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_embeddings</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_trace</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_enable_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">_log_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> \
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
        <span class="c1"># TODO(b/126388999): Remove step info in the summary name.</span>
        <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_export</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;batch_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">,</span>
            <span class="n">profiler_outdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">_log_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes metrics out as custom scalar summaries.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: Dict. Keys are scalar summary names, values are NumPy scalars.</span>
<span class="sd">        prefix: String. The prefix to apply to the scalar summary names.</span>
<span class="sd">        step: Int. The global step to use for TensorBoard.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Group metrics by the name of their associated file writer. Values</span>
    <span class="c1"># are lists of metrics, as (name, scalar_value) pairs.</span>
    <span class="n">logs_by_writer</span> <span class="o">=</span> <span class="p">{</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">:</span> <span class="p">[],</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
    <span class="n">validation_prefix</span> <span class="o">=</span> <span class="s1">&#39;val_&#39;</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;num_steps&#39;</span><span class="p">):</span>
        <span class="c1"># Scrub non-metric items.</span>
        <span class="k">continue</span>
      <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">validation_prefix</span><span class="p">):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_prefix</span><span class="p">):]</span>
        <span class="n">writer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">writer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span>
      <span class="n">name</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span>  <span class="c1"># assign batch or epoch prefix</span>
      <span class="n">logs_by_writer</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">writer_name</span> <span class="ow">in</span> <span class="n">logs_by_writer</span><span class="p">:</span>
          <span class="n">these_logs</span> <span class="o">=</span> <span class="n">logs_by_writer</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">these_logs</span><span class="p">:</span>
            <span class="c1"># Don&#39;t create a &quot;validation&quot; events file if we don&#39;t</span>
            <span class="c1"># actually have any validation data.</span>
            <span class="k">continue</span>
          <span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="n">writer_name</span><span class="p">)</span>
          <span class="k">with</span> <span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">these_logs</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs the weights of the Model to TensorBoard.&quot;&quot;&quot;</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">(),</span> \
          <span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> \
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
          <span class="n">weight_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
          <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_weight_as_image</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
      <span class="n">writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_log_weight_as_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs a weight as a TensorBoard image.&quot;&quot;&quot;</span>
    <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Bias case</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Dense layer kernel case</span>
      <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># ConvNet case</span>
      <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;channels_last&#39;</span><span class="p">:</span>
        <span class="c1"># Switch to channels_first to display every kernel as a separate</span>
        <span class="c1"># image.</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="c1"># Not possible to handle 3D convnets etc.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">w_img</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">embeddings_ckpt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
                                   <span class="s1">&#39;keras_embedding.ckpt-</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">embeddings_ckpt</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ReduceLROnPlateau&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Reduce learning rate when a metric has stopped improving.</span>

<span class="sd">  Models often benefit from reducing the learning rate by a factor</span>
<span class="sd">  of 2-10 once learning stagnates. This callback monitors a</span>
<span class="sd">  quantity and if no improvement is seen for a &#39;patience&#39; number</span>
<span class="sd">  of epochs, the learning rate is reduced.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2,</span>
<span class="sd">                                patience=5, min_lr=0.001)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[reduce_lr])</span>
<span class="sd">  ```</span>

<span class="sd">  Arguments:</span>
<span class="sd">      monitor: quantity to be monitored.</span>
<span class="sd">      factor: factor by which the learning rate will be reduced. new_lr = lr *</span>
<span class="sd">        factor</span>
<span class="sd">      patience: number of epochs with no improvement after which learning rate</span>
<span class="sd">        will be reduced.</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>
<span class="sd">      mode: one of {auto, min, max}. In `min` mode, lr will be reduced when the</span>
<span class="sd">        quantity monitored has stopped decreasing; in `max` mode it will be</span>
<span class="sd">        reduced when the quantity monitored has stopped increasing; in `auto`</span>
<span class="sd">        mode, the direction is automatically inferred from the name of the</span>
<span class="sd">        monitored quantity.</span>
<span class="sd">      min_delta: threshold for measuring the new optimum, to only focus on</span>
<span class="sd">        significant changes.</span>
<span class="sd">      cooldown: number of epochs to wait before resuming normal operation after</span>
<span class="sd">        lr has been reduced.</span>
<span class="sd">      min_lr: lower bound on the learning rate.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
               <span class="n">cooldown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">min_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceLROnPlateau</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="k">if</span> <span class="n">factor</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ReduceLROnPlateau &#39;</span> <span class="s1">&#39;does not support a factor &gt;= 1.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;epsilon&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">min_delta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;epsilon&#39;</span><span class="p">)</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`epsilon` argument is deprecated and &#39;</span>
                      <span class="s1">&#39;will be removed, use `min_delta` instead.&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span> <span class="o">=</span> <span class="n">cooldown</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Cooldown counter.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resets wait counter and cooldown counter.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Learning Rate Plateau Reducing mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span> <span class="ow">or</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span> <span class="ow">and</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Reduce LR on plateau conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
          <span class="n">old_lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
          <span class="k">if</span> <span class="n">old_lr</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">:</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="n">old_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">)</span>
            <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: ReduceLROnPlateau reducing learning &#39;</span>
                    <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">in_cooldown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.CSVLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CSVLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that streams epoch results to a csv file.</span>

<span class="sd">  Supports all values that can be represented as a string,</span>
<span class="sd">  including 1D iterables such as np.ndarray.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  csv_logger = CSVLogger(&#39;training.log&#39;)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[csv_logger])</span>
<span class="sd">  ```</span>

<span class="sd">  Arguments:</span>
<span class="sd">      filename: filename of the csv file, e.g. &#39;run/log.csv&#39;.</span>
<span class="sd">      separator: string used to separate elements in the csv file.</span>
<span class="sd">      append: True: append if file exists (useful for continuing</span>
<span class="sd">          training). False: overwrite existing file,</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sep</span> <span class="o">=</span> <span class="n">separator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append</span> <span class="o">=</span> <span class="n">append</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">six</span><span class="o">.</span><span class="n">PY2</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;newline&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">}</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CSVLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()))</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span>
                            <span class="n">mode</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span><span class="p">,</span>
                            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">handle_value</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
      <span class="n">is_zero_dim_ndarray</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">k</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_zero_dim_ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;&quot;[</span><span class="si">%s</span><span class="s1">]&quot;&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">)))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">k</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
      <span class="c1"># We set NA so that csv parsers do not fail for this last epoch.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span> <span class="k">else</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;NA&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>

      <span class="k">class</span> <span class="nc">CustomDialect</span><span class="p">(</span><span class="n">csv</span><span class="o">.</span><span class="n">excel</span><span class="p">):</span>
        <span class="n">delimiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sep</span>

      <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>
      <span class="k">if</span> <span class="n">six</span><span class="o">.</span><span class="n">PY2</span><span class="p">:</span>
        <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="n">unicode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">fieldnames</span><span class="p">]</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="p">,</span>
          <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">,</span>
          <span class="n">dialect</span><span class="o">=</span><span class="n">CustomDialect</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">row_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">({</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">})</span>
    <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">handle_value</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LambdaCallback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LambdaCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Callback for creating simple, custom callbacks on-the-fly.</span>

<span class="sd">  This callback is constructed with anonymous functions that will be called</span>
<span class="sd">  at the appropriate time. Note that the callbacks expects positional</span>
<span class="sd">  arguments, as:</span>

<span class="sd">   - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:</span>
<span class="sd">      `epoch`, `logs`</span>
<span class="sd">   - `on_batch_begin` and `on_batch_end` expect two positional arguments:</span>
<span class="sd">      `batch`, `logs`</span>
<span class="sd">   - `on_train_begin` and `on_train_end` expect one positional argument:</span>
<span class="sd">      `logs`</span>

<span class="sd">  Arguments:</span>
<span class="sd">      on_epoch_begin: called at the beginning of every epoch.</span>
<span class="sd">      on_epoch_end: called at the end of every epoch.</span>
<span class="sd">      on_batch_begin: called at the beginning of every batch.</span>
<span class="sd">      on_batch_end: called at the end of every batch.</span>
<span class="sd">      on_train_begin: called at the beginning of model training.</span>
<span class="sd">      on_train_end: called at the end of model training.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Print the batch number at the beginning of every batch.</span>
<span class="sd">  batch_print_callback = LambdaCallback(</span>
<span class="sd">      on_batch_begin=lambda batch,logs: print(batch))</span>

<span class="sd">  # Stream the epoch loss to a file in JSON format. The file content</span>
<span class="sd">  # is not well-formed JSON but rather has a JSON object per line.</span>
<span class="sd">  import json</span>
<span class="sd">  json_log = open(&#39;loss_log.json&#39;, mode=&#39;wt&#39;, buffering=1)</span>
<span class="sd">  json_logging_callback = LambdaCallback(</span>
<span class="sd">      on_epoch_end=lambda epoch, logs: json_log.write(</span>
<span class="sd">          json.dumps({&#39;epoch&#39;: epoch, &#39;loss&#39;: logs[&#39;loss&#39;]}) + &#39;\n&#39;),</span>
<span class="sd">      on_train_end=lambda logs: json_log.close()</span>
<span class="sd">  )</span>

<span class="sd">  # Terminate some processes after having finished model training.</span>
<span class="sd">  processes = ...</span>
<span class="sd">  cleanup_callback = LambdaCallback(</span>
<span class="sd">      on_train_end=lambda logs: [</span>
<span class="sd">          p.terminate() for p in processes if p.is_alive()])</span>

<span class="sd">  model.fit(...,</span>
<span class="sd">            callbacks=[batch_print_callback,</span>
<span class="sd">                       json_logging_callback,</span>
<span class="sd">                       cleanup_callback])</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">on_epoch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_epoch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LambdaCallback</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">on_epoch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="n">on_epoch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_epoch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="n">on_epoch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="n">on_batch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="n">on_batch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="n">on_train_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="n">on_train_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>